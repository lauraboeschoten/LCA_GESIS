[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Material Latent Class Analysis",
    "section": "",
    "text": "On this webpage, you can find all the course materials for the GESIS course “Latent Class Analysis”."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#day-1",
    "href": "index.html#day-1",
    "title": "Course Material Latent Class Analysis",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nTopic\nLecture\nLab\nExtra material\n\n\n\n\nIntroduction\nLecture Introduction\n-\n-\n\n\nEM algorithm\nLecture EM\nLab EM\n-\n\n\nLCA basics\nLecture LCA basics\nLab LCA\nLCA_Excel\nLab dataset"
  },
  {
    "objectID": "Labs/Day_1/Lab_EM/3_Lab_EM.html",
    "href": "Labs/Day_1/Lab_EM/3_Lab_EM.html",
    "title": "EM: simple example",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of univariate Gaussians, and estimate that mixture (LPA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job.\nYou can copy code into your R environment by clicking the copy icon in the top right of each code block. You can also obtain the source code for this entire document by clicking “Code” at the top-right of this page.\n\nLook through the code and make the exercises. Your instructor is of course around to help and collaboration among participants is encouraged.\nBelow the regular questions, you will find a few “BONUS” questions. These are for those among you who are looking for a serious challenge, and you will likely find the difficulty level of these questions considerably higher. Do not worry if you do not understand these BONUS questions. Their completion is not needed for an applied understanding of LCA!\nQuestion 1\n\nset.seed(201505) # To reproduce the same \"random\" numbers\n# These are actual estimated values from the NHANES study.\n# We will take these as the true means and standard deviations \ntrue_mean_men &lt;- 1.74#m\ntrue_mean_women &lt;- 1.58#m\ntrue_sd_men &lt;- 0.08#m\ntrue_sd_women &lt;- 0.07#m\n\n# Generate fake data from the mixture distribution\nn &lt;- 1000 # Sample size\ntrue_sex &lt;- rbinom(n, size = 1, prob=0.5) + 1\n# Height is normally distributed but with different means and stdevs for men and women.\nheight &lt;- rnorm(n, c(true_mean_men, true_mean_women)[true_sex], \n                c(true_sd_men, true_sd_women)[true_sex])\n\n# Look at the data\nhist(height)\n\n\n\n\n\n\n\nRead the simulation code. Do you understand the code? Can you explain in your own words what happens here? Do you have any questions?\nQuestion 2\n\nrunit &lt;- function(maxit=3, sep_start=0.2) {\n  \n  # Choose some starting values. I choose inaccurate ones on purpose here\n  guess_mean_men &lt;- mean(height) + sep_start # We need to start with differences\n  guess_mean_wom &lt;- mean(height) - sep_start\n  guess_sd_men &lt;- sd(height)\n  guess_sd_wom &lt;- sd(height)\n  \n  cat(\"Iter:\\tM:\\tF:\\tsd(M):\\tsd(F):\\t\\n---------------------------------------\\n\")\n  cat(sprintf(\"Start\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", \n              guess_mean_men, guess_mean_wom, \n              guess_sd_men, guess_sd_wom))\n  \n  for(it in 1:maxit) {\n    # Posterior probability of being a man is the estimated proportion of the \n    #    overall height of the probability curve for men+women \n    #    that is made up by the probability curve for men:\n    pman &lt;- dnorm(height, mean = guess_mean_men, sd = guess_sd_men)\n    pwom &lt;- dnorm(height, mean = guess_mean_wom, sd = guess_sd_wom)\n    \n    post &lt;- pman / (pman + pwom)\n    \n    # The means and standard deviations for the groups of men and women are\n    #    obtained simply by using the posterior probabilities as weights. \n    # E.g. somebody with posterior 0.8 of being a man is counted 80% towards\n    #    the mean of men, and 20% towards that of women.\n    guess_mean_men &lt;- weighted.mean(height, w = post)\n    guess_mean_wom &lt;- weighted.mean(height, w = 1-post)\n    \n    guess_sd_men &lt;- sqrt(weighted.mean((height - guess_mean_men)^2, w = post))\n    guess_sd_wom &lt;- sqrt(weighted.mean((height - guess_mean_wom)^2, w = 1-post))\n    \n    # Output some of the results\n    cat(sprintf(\"%d\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", it,\n                guess_mean_men, guess_mean_wom, \n                guess_sd_men, guess_sd_wom))\n  }\n  \n  return(post) # Return the posterior probability of being a man\n}\n\nRead the function runit. Do you understand all steps?\nQuestion 3\nCode understanding check:\n\na. Why is the function dnorm used? Why is it used twice?\nb. What is happening here: post &lt;- pman / (pman + pwom)? What is the intuitive explanation of this formula?\nc. Why is weighted.mean used rather than just mean?\nd. Why are the weights chosen the way they are? e. What is the function of the for loop? When will it stop? Can you think of a different stopping rule?\n\nNow run the EM algorithm using our very own runit function.\n\n## Run the model!\n\n# Use height data to run the EM algorithm that estimates the means and stdevs of\n#    interest. Some intermediate output will be written to the screen.\npost &lt;- runit(maxit=5, sep_start=0.2)\n\nIter:   M:  F:  sd(M):  sd(F):  \n---------------------------------------\nStart   1.86    1.46    0.107   0.107\n1   1.74    1.58    0.072   0.066\n2   1.74    1.58    0.072   0.066\n3   1.74    1.58    0.073   0.066\n4   1.74    1.58    0.073   0.065\n5   1.74    1.58    0.073   0.065\n\n\nQuestion 4\nModel understanding check:\n\na. How does the EM algorithm know which group refers to men and which group refers to women? (Hint: this is a trick question)\nb. What is the height of the normal distribution curve (probability density) for: i. A 1.5 meter tall man ii. A 1.8 meter tall man iii. A 1.5 meter tall woman iv. A 1.8 meter tall woman\nc. From part (b), calculate the posterior probability to belong to the “women” class for: i. A 1.5 meter tall person of unknown sex (That is, calculate \\(P(\\text{Sex}=\\text{Woman} | \\text{Height} = 1.5)\\)) ii. A 1.8 meter tall person of unknown sex (same as above).\n\nQuestion 5\nGuessing people’s sex based on their posterior probability is not perfect. We can see this by making a cross-table between the guessed class and the true class (which here we happen to know because we created that variable ourselves in the simulation). So we guess the class based on the posterior probability and then tabulate this against the true class.\n\nsex &lt;- as.factor(true_sex)\n# Guess woman if posterior probability of being a man is less than 50%:\nguess_person_sex &lt;- as.factor(post &lt; 0.5) \nlevels(sex) &lt;- levels(guess_person_sex) &lt;- c(\"Man\", \"Woman\")\n\nknitr::kable(table(guess_person_sex, true_sex))\n\n\n\n\n1\n2\n\n\n\nMan\n436\n60\n\n\nWoman\n83\n421\n\n\n\n\n\nThis table gives the probability of being classified as a man/woman, given that you truly are one:\n\ntable(guess_person_sex, true_sex) |&gt;\n  prop.table(2) |&gt;\n  knitr::kable(digits = 4)\n\n\n\n\n1\n2\n\n\n\nMan\n0.8401\n0.1247\n\n\nWoman\n0.1599\n0.8753\n\n\n\n\n\nThis table is sometimes called the classification table. It is a measure of separation between the classes, and plays an important role when you want to use the classifications for some subsequent analysis. In practice, it cannot be calculated because we do not have the true_sex. Instead, an estimate can be calculated using the posterior probabilities. If these are well-calibrated (correspond to the true uncertainty about class membership), then calculating the within-guess mean of the posterior should give the desired classification table.\n\ncount_guesses &lt;- tabulate(guess_person_sex)\n\ntab &lt;- rbind(\n  tapply(post, guess_person_sex, mean), \n  tapply(1 - post, guess_person_sex, mean))\n\n# The table now estimates the probability of true class given guess. \n# We first recalculate this to a simple crosstable with counts.\nt(tab * count_guesses) |&gt; knitr::kable(digits = 1)\n\n\n\nMan\n439.5\n57.4\n\n\nWoman\n60.6\n442.4\n\n\n\n\nAgain we can show the table using column proportions, to give an estimate of the chance of correct classification given true class membership.\n\nt(tab * count_guesses) |&gt; \n  prop.table(2) |&gt;\n  knitr::kable(digits = 4)\n\n\n\nMan\n0.8788\n0.1148\n\n\nWoman\n0.1212\n0.8852\n\n\n\n\nQuestion 6\nBy changing the values of the relevant variables below, experiment with different settings for the means and standard deviations. Attempt to create a situation in which:\n\nThe cross-table between guessed class and true class is near-perfect;\nThe cross-table between guessed class and true class is near-useless.\n\nWhat do you conclude?\nQuestion 7\nChange the sample size to the following settings and report your findings: \\(n = 20, 50, 100, 500, 1000, 10000\\). (Be sure to re-set the parameter values for the means and standard deviations to their original values).\nQuestion 8\nUsing flexmix, we can run the same model.\n\n# Do the same as above with the flexmix library:\nlibrary(flexmix)\nheight_fit_flexmix &lt;- flexmix(height ~ 1, k = 2)\nparameters(height_fit_flexmix)\n\n                    Comp.1    Comp.2\ncoef.(Intercept) 1.6619860 1.6578146\nsigma            0.1078282 0.1070786\n\n\nSometimes flexmix converges to a local optimum. To solve this problem,we use multiple random starts (nrep = 100):\n\nheight_fit_flexmix &lt;- stepFlexmix(height ~ 1, k = 2, nrep = 100)\n\n2 : * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\nparameters(height_fit_flexmix)\n\n                     Comp.1     Comp.2\ncoef.(Intercept) 1.73242753 1.56980509\nsigma            0.07715975 0.06194694\n\n\nWe can also use mclust.\n\n# Or using the mclust library\nlibrary(mclust)\nheight_fit_mclust &lt;- Mclust(height)\nsummary(height_fit_mclust, parameters = TRUE)\n\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust E (univariate, equal variance) model with 2 components: \n\n log-likelihood    n df      BIC      ICL\n       835.7496 1000  4 1643.868 1367.668\n\nClustering table:\n  1   2 \n542 458 \n\nMixing probabilities:\n        1         2 \n0.5365927 0.4634073 \n\nMeans:\n       1        2 \n1.583406 1.748475 \n\nVariances:\n          1           2 \n0.004763713 0.004763713 \n\n\nRun the code above to confirm that we can achieve the same result by using R packages.\nQuestion 9\nBONUS: In this exercise, we completely ignored the fact that the “prior” probabilities \\(\\pi = P(\\text{Sex} = \\text{Woman})\\) and \\(1-\\pi\\), which determine the class sizes, are not really known in practice. In other words, we set \\(\\pi\\) to its true value, \\(\\pi = 0.5\\) in our implementation. In practice, \\(\\pi\\) will be a parameter to be estimated. Implement code that does this. (Hint: you will need to adjust the E-step by using Bayes rule. The M-step for \\(\\pi\\) is just pi_est = mean(post).) Check your code by setting n to a large value, changing prob=0.5 in the simulation code to some substantially different number, and checking that your estimate corresponds to the true value. 8.\nQuestion 10 (BONUS)\nThe log-likelihood for this model is \\[\n    \\ell(\\mu_1, \\mu_2, \\sigma_1, \\sigma_2 ; y) = \\sum_{i = 1}^n \\ln \\left[\n      \\pi \\cdot \\text{Normal}(\\mu_1, \\sigma_1) +\n      (1-\\pi) \\text{Normal}(\\mu_2, \\sigma_2)\n    \\right].\n    \\] Write code that calculates this log-likelihood, loglik, at each iteration of the EM for-loop. Double-check your code against the output of flexmix (or another package that provides this output). 9.\nQuestion 11 (BONUS)\nUsing the result from (9), implement code that terminates the for loop when the absolute relative decrease in log-likelihood, abs((loglik_current - loglik_previous)/loglik_current), say, is less than a tolerance value such as 0.001."
  },
  {
    "objectID": "Labs/Day_1/Lab_EM/3_Lab_EM.html#exercises",
    "href": "Labs/Day_1/Lab_EM/3_Lab_EM.html#exercises",
    "title": "EM: simple example",
    "section": "",
    "text": "Look through the code and make the exercises. Your instructor is of course around to help and collaboration among participants is encouraged.\nBelow the regular questions, you will find a few “BONUS” questions. These are for those among you who are looking for a serious challenge, and you will likely find the difficulty level of these questions considerably higher. Do not worry if you do not understand these BONUS questions. Their completion is not needed for an applied understanding of LCA!\nQuestion 1\n\nset.seed(201505) # To reproduce the same \"random\" numbers\n# These are actual estimated values from the NHANES study.\n# We will take these as the true means and standard deviations \ntrue_mean_men &lt;- 1.74#m\ntrue_mean_women &lt;- 1.58#m\ntrue_sd_men &lt;- 0.08#m\ntrue_sd_women &lt;- 0.07#m\n\n# Generate fake data from the mixture distribution\nn &lt;- 1000 # Sample size\ntrue_sex &lt;- rbinom(n, size = 1, prob=0.5) + 1\n# Height is normally distributed but with different means and stdevs for men and women.\nheight &lt;- rnorm(n, c(true_mean_men, true_mean_women)[true_sex], \n                c(true_sd_men, true_sd_women)[true_sex])\n\n# Look at the data\nhist(height)\n\n\n\n\n\n\n\nRead the simulation code. Do you understand the code? Can you explain in your own words what happens here? Do you have any questions?\nQuestion 2\n\nrunit &lt;- function(maxit=3, sep_start=0.2) {\n  \n  # Choose some starting values. I choose inaccurate ones on purpose here\n  guess_mean_men &lt;- mean(height) + sep_start # We need to start with differences\n  guess_mean_wom &lt;- mean(height) - sep_start\n  guess_sd_men &lt;- sd(height)\n  guess_sd_wom &lt;- sd(height)\n  \n  cat(\"Iter:\\tM:\\tF:\\tsd(M):\\tsd(F):\\t\\n---------------------------------------\\n\")\n  cat(sprintf(\"Start\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", \n              guess_mean_men, guess_mean_wom, \n              guess_sd_men, guess_sd_wom))\n  \n  for(it in 1:maxit) {\n    # Posterior probability of being a man is the estimated proportion of the \n    #    overall height of the probability curve for men+women \n    #    that is made up by the probability curve for men:\n    pman &lt;- dnorm(height, mean = guess_mean_men, sd = guess_sd_men)\n    pwom &lt;- dnorm(height, mean = guess_mean_wom, sd = guess_sd_wom)\n    \n    post &lt;- pman / (pman + pwom)\n    \n    # The means and standard deviations for the groups of men and women are\n    #    obtained simply by using the posterior probabilities as weights. \n    # E.g. somebody with posterior 0.8 of being a man is counted 80% towards\n    #    the mean of men, and 20% towards that of women.\n    guess_mean_men &lt;- weighted.mean(height, w = post)\n    guess_mean_wom &lt;- weighted.mean(height, w = 1-post)\n    \n    guess_sd_men &lt;- sqrt(weighted.mean((height - guess_mean_men)^2, w = post))\n    guess_sd_wom &lt;- sqrt(weighted.mean((height - guess_mean_wom)^2, w = 1-post))\n    \n    # Output some of the results\n    cat(sprintf(\"%d\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", it,\n                guess_mean_men, guess_mean_wom, \n                guess_sd_men, guess_sd_wom))\n  }\n  \n  return(post) # Return the posterior probability of being a man\n}\n\nRead the function runit. Do you understand all steps?\nQuestion 3\nCode understanding check:\n\na. Why is the function dnorm used? Why is it used twice?\nb. What is happening here: post &lt;- pman / (pman + pwom)? What is the intuitive explanation of this formula?\nc. Why is weighted.mean used rather than just mean?\nd. Why are the weights chosen the way they are? e. What is the function of the for loop? When will it stop? Can you think of a different stopping rule?\n\nNow run the EM algorithm using our very own runit function.\n\n## Run the model!\n\n# Use height data to run the EM algorithm that estimates the means and stdevs of\n#    interest. Some intermediate output will be written to the screen.\npost &lt;- runit(maxit=5, sep_start=0.2)\n\nIter:   M:  F:  sd(M):  sd(F):  \n---------------------------------------\nStart   1.86    1.46    0.107   0.107\n1   1.74    1.58    0.072   0.066\n2   1.74    1.58    0.072   0.066\n3   1.74    1.58    0.073   0.066\n4   1.74    1.58    0.073   0.065\n5   1.74    1.58    0.073   0.065\n\n\nQuestion 4\nModel understanding check:\n\na. How does the EM algorithm know which group refers to men and which group refers to women? (Hint: this is a trick question)\nb. What is the height of the normal distribution curve (probability density) for: i. A 1.5 meter tall man ii. A 1.8 meter tall man iii. A 1.5 meter tall woman iv. A 1.8 meter tall woman\nc. From part (b), calculate the posterior probability to belong to the “women” class for: i. A 1.5 meter tall person of unknown sex (That is, calculate \\(P(\\text{Sex}=\\text{Woman} | \\text{Height} = 1.5)\\)) ii. A 1.8 meter tall person of unknown sex (same as above).\n\nQuestion 5\nGuessing people’s sex based on their posterior probability is not perfect. We can see this by making a cross-table between the guessed class and the true class (which here we happen to know because we created that variable ourselves in the simulation). So we guess the class based on the posterior probability and then tabulate this against the true class.\n\nsex &lt;- as.factor(true_sex)\n# Guess woman if posterior probability of being a man is less than 50%:\nguess_person_sex &lt;- as.factor(post &lt; 0.5) \nlevels(sex) &lt;- levels(guess_person_sex) &lt;- c(\"Man\", \"Woman\")\n\nknitr::kable(table(guess_person_sex, true_sex))\n\n\n\n\n1\n2\n\n\n\nMan\n436\n60\n\n\nWoman\n83\n421\n\n\n\n\n\nThis table gives the probability of being classified as a man/woman, given that you truly are one:\n\ntable(guess_person_sex, true_sex) |&gt;\n  prop.table(2) |&gt;\n  knitr::kable(digits = 4)\n\n\n\n\n1\n2\n\n\n\nMan\n0.8401\n0.1247\n\n\nWoman\n0.1599\n0.8753\n\n\n\n\n\nThis table is sometimes called the classification table. It is a measure of separation between the classes, and plays an important role when you want to use the classifications for some subsequent analysis. In practice, it cannot be calculated because we do not have the true_sex. Instead, an estimate can be calculated using the posterior probabilities. If these are well-calibrated (correspond to the true uncertainty about class membership), then calculating the within-guess mean of the posterior should give the desired classification table.\n\ncount_guesses &lt;- tabulate(guess_person_sex)\n\ntab &lt;- rbind(\n  tapply(post, guess_person_sex, mean), \n  tapply(1 - post, guess_person_sex, mean))\n\n# The table now estimates the probability of true class given guess. \n# We first recalculate this to a simple crosstable with counts.\nt(tab * count_guesses) |&gt; knitr::kable(digits = 1)\n\n\n\nMan\n439.5\n57.4\n\n\nWoman\n60.6\n442.4\n\n\n\n\nAgain we can show the table using column proportions, to give an estimate of the chance of correct classification given true class membership.\n\nt(tab * count_guesses) |&gt; \n  prop.table(2) |&gt;\n  knitr::kable(digits = 4)\n\n\n\nMan\n0.8788\n0.1148\n\n\nWoman\n0.1212\n0.8852\n\n\n\n\nQuestion 6\nBy changing the values of the relevant variables below, experiment with different settings for the means and standard deviations. Attempt to create a situation in which:\n\nThe cross-table between guessed class and true class is near-perfect;\nThe cross-table between guessed class and true class is near-useless.\n\nWhat do you conclude?\nQuestion 7\nChange the sample size to the following settings and report your findings: \\(n = 20, 50, 100, 500, 1000, 10000\\). (Be sure to re-set the parameter values for the means and standard deviations to their original values).\nQuestion 8\nUsing flexmix, we can run the same model.\n\n# Do the same as above with the flexmix library:\nlibrary(flexmix)\nheight_fit_flexmix &lt;- flexmix(height ~ 1, k = 2)\nparameters(height_fit_flexmix)\n\n                    Comp.1    Comp.2\ncoef.(Intercept) 1.6619860 1.6578146\nsigma            0.1078282 0.1070786\n\n\nSometimes flexmix converges to a local optimum. To solve this problem,we use multiple random starts (nrep = 100):\n\nheight_fit_flexmix &lt;- stepFlexmix(height ~ 1, k = 2, nrep = 100)\n\n2 : * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\nparameters(height_fit_flexmix)\n\n                     Comp.1     Comp.2\ncoef.(Intercept) 1.73242753 1.56980509\nsigma            0.07715975 0.06194694\n\n\nWe can also use mclust.\n\n# Or using the mclust library\nlibrary(mclust)\nheight_fit_mclust &lt;- Mclust(height)\nsummary(height_fit_mclust, parameters = TRUE)\n\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust E (univariate, equal variance) model with 2 components: \n\n log-likelihood    n df      BIC      ICL\n       835.7496 1000  4 1643.868 1367.668\n\nClustering table:\n  1   2 \n542 458 \n\nMixing probabilities:\n        1         2 \n0.5365927 0.4634073 \n\nMeans:\n       1        2 \n1.583406 1.748475 \n\nVariances:\n          1           2 \n0.004763713 0.004763713 \n\n\nRun the code above to confirm that we can achieve the same result by using R packages.\nQuestion 9\nBONUS: In this exercise, we completely ignored the fact that the “prior” probabilities \\(\\pi = P(\\text{Sex} = \\text{Woman})\\) and \\(1-\\pi\\), which determine the class sizes, are not really known in practice. In other words, we set \\(\\pi\\) to its true value, \\(\\pi = 0.5\\) in our implementation. In practice, \\(\\pi\\) will be a parameter to be estimated. Implement code that does this. (Hint: you will need to adjust the E-step by using Bayes rule. The M-step for \\(\\pi\\) is just pi_est = mean(post).) Check your code by setting n to a large value, changing prob=0.5 in the simulation code to some substantially different number, and checking that your estimate corresponds to the true value. 8.\nQuestion 10 (BONUS)\nThe log-likelihood for this model is \\[\n    \\ell(\\mu_1, \\mu_2, \\sigma_1, \\sigma_2 ; y) = \\sum_{i = 1}^n \\ln \\left[\n      \\pi \\cdot \\text{Normal}(\\mu_1, \\sigma_1) +\n      (1-\\pi) \\text{Normal}(\\mu_2, \\sigma_2)\n    \\right].\n    \\] Write code that calculates this log-likelihood, loglik, at each iteration of the EM for-loop. Double-check your code against the output of flexmix (or another package that provides this output). 9.\nQuestion 11 (BONUS)\nUsing the result from (9), implement code that terminates the for loop when the absolute relative decrease in log-likelihood, abs((loglik_current - loglik_previous)/loglik_current), say, is less than a tolerance value such as 0.001."
  },
  {
    "objectID": "Labs/Day_1/Lab_LCA/5_Exercise.html",
    "href": "Labs/Day_1/Lab_LCA/5_Exercise.html",
    "title": "Exercise: Anti-religious speech",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(poLCA)\n\nRead the data from the General Social Survey 1987. It’s not old, it’s a classic!\n\nantireli &lt;- read.csv(\"https://daob.nl/files/lca/antireli_data.csv\")\n\nhead(antireli)\n\n  Y1 Y2 Y3\n1  1  1  1\n2  1  1  1\n3  1  1  1\n4  1  1  1\n5  1  1  1\n6  1  1  1\n\n\nShow the data as pattern frequencies.\n\ntable(antireli) |&gt; knitr::kable()\n\n\n\nY1\nY2\nY3\nFreq\n\n\n\n1\n1\n1\n696\n\n\n2\n1\n1\n34\n\n\n1\n2\n1\n275\n\n\n2\n2\n1\n125\n\n\n1\n1\n2\n68\n\n\n2\n1\n2\n19\n\n\n1\n2\n2\n130\n\n\n2\n2\n2\n366\n\n\n\n\n\nQuestion 1\nUse poLCA and fit a two-class LCA to these data.\n\nfit &lt;- poLCA(cbind(Y1, Y2, Y3) ~ 1, \n             data = antireli, \n             nclass = 2)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$Y1\n           Pr(1)  Pr(2)\nclass 1:  0.9601 0.0399\nclass 2:  0.2284 0.7716\n\n$Y2\n           Pr(1)  Pr(2)\nclass 1:  0.7424 0.2576\nclass 2:  0.0429 0.9571\n\n$Y3\n           Pr(1)  Pr(2)\nclass 1:  0.9166 0.0834\nclass 2:  0.2395 0.7605\n\nEstimated class population shares \n 0.6205 0.3795 \n \nPredicted class memberships (by modal posterior prob.) \n 0.6264 0.3736 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 1713 \nnumber of estimated parameters: 7 \nresidual degrees of freedom: 0 \nmaximum log-likelihood: -2795.376 \n \nAIC(2): 5604.751\nBIC(2): 5642.873\nG^2(2): 2.878816e-10 (Likelihood ratio/deviance statistic) \nX^2(2): 2.374666e-10 (Chi-square goodness of fit) \n \n\n\nQuestion 2\nCreate a profile plot.\n\nplot(fit)\n\n\n\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %&gt;% \n  filter(outcome == 2) %&gt;% \n  mutate(class = as.factor(class)) %&gt;%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() +  scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\nQuestion 3\nHow would you label the classes?\nQuestion 4\nWhat can you say about the estimated class sizes? What does this mean for the prevalence of the attitudes you labeled under (3)?\nQuestion 5\nModel fit\n\na. How many parameters are there?\nb. How many unique data patterns are there (fixing the sample size \\(n=1713\\))?\nc. Can you explain the number of degrees of freedom?\nd. Can you explain the value of the G^2 (\\(G^2\\)) and X^2 (\\(\\chi^2\\)) statistics?"
  },
  {
    "objectID": "Labs/Day_1/Lab_LCA/5_Exercise.html#exercises",
    "href": "Labs/Day_1/Lab_LCA/5_Exercise.html#exercises",
    "title": "Exercise: Anti-religious speech",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(poLCA)\n\nRead the data from the General Social Survey 1987. It’s not old, it’s a classic!\n\nantireli &lt;- read.csv(\"https://daob.nl/files/lca/antireli_data.csv\")\n\nhead(antireli)\n\n  Y1 Y2 Y3\n1  1  1  1\n2  1  1  1\n3  1  1  1\n4  1  1  1\n5  1  1  1\n6  1  1  1\n\n\nShow the data as pattern frequencies.\n\ntable(antireli) |&gt; knitr::kable()\n\n\n\nY1\nY2\nY3\nFreq\n\n\n\n1\n1\n1\n696\n\n\n2\n1\n1\n34\n\n\n1\n2\n1\n275\n\n\n2\n2\n1\n125\n\n\n1\n1\n2\n68\n\n\n2\n1\n2\n19\n\n\n1\n2\n2\n130\n\n\n2\n2\n2\n366\n\n\n\n\n\nQuestion 1\nUse poLCA and fit a two-class LCA to these data.\n\nfit &lt;- poLCA(cbind(Y1, Y2, Y3) ~ 1, \n             data = antireli, \n             nclass = 2)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$Y1\n           Pr(1)  Pr(2)\nclass 1:  0.9601 0.0399\nclass 2:  0.2284 0.7716\n\n$Y2\n           Pr(1)  Pr(2)\nclass 1:  0.7424 0.2576\nclass 2:  0.0429 0.9571\n\n$Y3\n           Pr(1)  Pr(2)\nclass 1:  0.9166 0.0834\nclass 2:  0.2395 0.7605\n\nEstimated class population shares \n 0.6205 0.3795 \n \nPredicted class memberships (by modal posterior prob.) \n 0.6264 0.3736 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 1713 \nnumber of estimated parameters: 7 \nresidual degrees of freedom: 0 \nmaximum log-likelihood: -2795.376 \n \nAIC(2): 5604.751\nBIC(2): 5642.873\nG^2(2): 2.878816e-10 (Likelihood ratio/deviance statistic) \nX^2(2): 2.374666e-10 (Chi-square goodness of fit) \n \n\n\nQuestion 2\nCreate a profile plot.\n\nplot(fit)\n\n\n\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %&gt;% \n  filter(outcome == 2) %&gt;% \n  mutate(class = as.factor(class)) %&gt;%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() +  scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\nQuestion 3\nHow would you label the classes?\nQuestion 4\nWhat can you say about the estimated class sizes? What does this mean for the prevalence of the attitudes you labeled under (3)?\nQuestion 5\nModel fit\n\na. How many parameters are there?\nb. How many unique data patterns are there (fixing the sample size \\(n=1713\\))?\nc. Can you explain the number of degrees of freedom?\nd. Can you explain the value of the G^2 (\\(G^2\\)) and X^2 (\\(\\chi^2\\)) statistics?"
  },
  {
    "objectID": "index.html#day-2",
    "href": "index.html#day-2",
    "title": "Course Material Latent Class Analysis",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nTopic\nLecture\nLab\nExtra material\n\n\n\n\nModel fit\nLecture model fit\nLab model fit\n-\n\n\nClassification and covariates\nLecture classification and covariates\nLab classification and covariates\nExercise 1\n\n\nBayes rule and EM categorical\nLecture Bayes rule\nLecture EM categorical\nLab EM categorical\nExercise 2"
  },
  {
    "objectID": "Labs/Day_2/Lab_1/2_Lab.html",
    "href": "Labs/Day_2/Lab_1/2_Lab.html",
    "title": "Lab part 1: Political activism in Greece",
    "section": "",
    "text": "set.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(haven)\nlibrary(poLCA)\n\n\nQuestion 1\nRead the data from the European Social Survey, round 4 (Greece).\nFor each of these survey questions, 1=“Yes” and 2=“No”.\n\n\ncontplt - Contacted politician or government official last 12 months\n\nwrkprty - Worked in political party or action group last 12 months\n\nwrkorg - Worked in another organisation or association last 12 months\n\nbadge - Worn or displayed campaign badge/sticker last 12 months\n\nsgnptit - Signed petition last 12 months\n\npbldmn - Taken part in lawful public demonstration last 12 months\n\nbctprd - Boycotted certain products last 12 months\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\n\ness_greece &lt;- read_csv(\"https://daob.nl/files/lca/ess_greece.csv.gz\") \n\ness_greece |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n\nQuestion 2\nSadly, poLCA has no way of dealing with missing values other than “listwise deletion” (na.omit). For later comparability of models with different sets of variables, we create a single dataset without missings.\n\ness_greece &lt;- na.omit(ess_greece)\n\nQuestion 3\nWhat are the pattern frequencies of the data?\n\ntable(ess_greece) %&gt;% \n  as.data.frame() %&gt;%\n  filter(Freq != 0) %&gt;% \n  rmarkdown::paged_table()\n\n\n  \n\n\n\nQuestion 4\nCreate a convenience function that will fit the K-class model to the political participation data.\n\nfitLCA &lt;- function(k) {\n  f &lt;- cbind(contplt, wrkprty, wrkorg, badge, \n           sgnptit, pbldmn, bctprd) ~ 1\n  \n  poLCA(formula = f, data = ess_greece, nclass = k, \n        nrep = 10, verbose = FALSE)\n}\n\nQuestion 4\nApply the function to successively increasingly classes K = 1, 2, 3, …, 6. (Note: this can take a while!)\n\nMK &lt;- lapply(1:6, fitLCA)\n\nQuestion 5\nCompare the fit of the different models by looking at AIC, BIC, etc.\n\naic_values &lt;- sapply(MK, `[[`, \"aic\")\nbic_values &lt;- sapply(MK, `[[`, \"bic\")\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"AIC\", las = 2)\n\n\n\n\n\n\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"BIC\", las = 2)\n\n\n\n\n\n\n\nQuestion 5\nWhich model do you select? Print the profile of your selected model.\n\nform_activism &lt;- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ 1\n\nfit &lt;- poLCA(form_activism, \n             data = ess_greece, \n             nclass = 4, \n             nrep = 20, verbose = FALSE)\n\nQuestion 6 Now plot the profile of your selected model. How would you substantively interpret the classes of this model?\nThis is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %&gt;% # from `broom` package\n  filter(outcome == 2) %&gt;% \n  mutate(class = as.factor(class)) %&gt;%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "Labs/Day_2/Lab_1/2_Lab.html#political-activism-in-ess",
    "href": "Labs/Day_2/Lab_1/2_Lab.html#political-activism-in-ess",
    "title": "Lab part 1: Political activism in Greece",
    "section": "",
    "text": "set.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(haven)\nlibrary(poLCA)\n\n\nQuestion 1\nRead the data from the European Social Survey, round 4 (Greece).\nFor each of these survey questions, 1=“Yes” and 2=“No”.\n\n\ncontplt - Contacted politician or government official last 12 months\n\nwrkprty - Worked in political party or action group last 12 months\n\nwrkorg - Worked in another organisation or association last 12 months\n\nbadge - Worn or displayed campaign badge/sticker last 12 months\n\nsgnptit - Signed petition last 12 months\n\npbldmn - Taken part in lawful public demonstration last 12 months\n\nbctprd - Boycotted certain products last 12 months\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\n\ness_greece &lt;- read_csv(\"https://daob.nl/files/lca/ess_greece.csv.gz\") \n\ness_greece |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n\nQuestion 2\nSadly, poLCA has no way of dealing with missing values other than “listwise deletion” (na.omit). For later comparability of models with different sets of variables, we create a single dataset without missings.\n\ness_greece &lt;- na.omit(ess_greece)\n\nQuestion 3\nWhat are the pattern frequencies of the data?\n\ntable(ess_greece) %&gt;% \n  as.data.frame() %&gt;%\n  filter(Freq != 0) %&gt;% \n  rmarkdown::paged_table()\n\n\n  \n\n\n\nQuestion 4\nCreate a convenience function that will fit the K-class model to the political participation data.\n\nfitLCA &lt;- function(k) {\n  f &lt;- cbind(contplt, wrkprty, wrkorg, badge, \n           sgnptit, pbldmn, bctprd) ~ 1\n  \n  poLCA(formula = f, data = ess_greece, nclass = k, \n        nrep = 10, verbose = FALSE)\n}\n\nQuestion 4\nApply the function to successively increasingly classes K = 1, 2, 3, …, 6. (Note: this can take a while!)\n\nMK &lt;- lapply(1:6, fitLCA)\n\nQuestion 5\nCompare the fit of the different models by looking at AIC, BIC, etc.\n\naic_values &lt;- sapply(MK, `[[`, \"aic\")\nbic_values &lt;- sapply(MK, `[[`, \"bic\")\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"AIC\", las = 2)\n\n\n\n\n\n\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"BIC\", las = 2)\n\n\n\n\n\n\n\nQuestion 5\nWhich model do you select? Print the profile of your selected model.\n\nform_activism &lt;- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ 1\n\nfit &lt;- poLCA(form_activism, \n             data = ess_greece, \n             nclass = 4, \n             nrep = 20, verbose = FALSE)\n\nQuestion 6 Now plot the profile of your selected model. How would you substantively interpret the classes of this model?\nThis is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %&gt;% # from `broom` package\n  filter(outcome == 2) %&gt;% \n  mutate(class = as.factor(class)) %&gt;%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "Labs/Day_2/Lab_2/4_Lab.html",
    "href": "Labs/Day_2/Lab_2/4_Lab.html",
    "title": "Lab part 2: Political activisim in Greece",
    "section": "",
    "text": "Classification quality\nIn Lab 2, we continue with the model we created in Lab 1. You can continue in your previous script with the four class model, or run the following code:\n\nset.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(haven)\nlibrary(poLCA)\nlibrary(ggplot2)\n\ness_greece &lt;- read_csv(\"https://daob.nl/files/lca/ess_greece.csv.gz\") \ness_greece &lt;- na.omit(ess_greece)\n\nform_activism &lt;- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ 1\n\nfit &lt;- poLCA(form_activism, \n             data = ess_greece, \n             nclass = 4, \n             nrep = 20, verbose = FALSE)\n\nQuestion 1\nCreate a data frame with the posterior class memberships and predicted class has the actual classification (predclass is the “modal assignment”)\nUse the four-class model as the selected model\n\nposteriors &lt;- data.frame(post = fit$posterior,\n                         predclass = fit$predclass)\n\nclassification_table &lt;- posteriors %&gt;% \n  group_by(predclass) %&gt;% \n  summarize(across(starts_with(\"post.\"), ~ sum(.x)))\n\nclassification_table &lt;- classification_table[,-1] |&gt; as.matrix()\n\n# Adopt the notation X=true latent class, W=assigned class\ncolnames(classification_table) &lt;- paste0(\"X=\", 1:4)\nrownames(classification_table) &lt;- paste0(\"W=\", 1:4)\n\nclassification_table %&gt;% round(1)\n\n     X=1  X=2  X=3    X=4\nW=1 60.1  1.4  8.6    4.0\nW=2  0.2 19.8  1.0    0.0\nW=3  3.0  1.1 87.4    7.5\nW=4 11.1  0.0 34.8 1822.0\n\n\nWith column proportions:\n\nclassification_table |&gt;\n  prop.table(2) |&gt; \n  round(3)\n\n      X=1   X=2   X=3   X=4\nW=1 0.808 0.062 0.065 0.002\nW=2 0.003 0.887 0.008 0.000\nW=3 0.040 0.051 0.663 0.004\nW=4 0.149 0.000 0.264 0.994\n\n\nQuestion 2\nCalculate classification errors from classification table.\n\n1 - sum(diag(classification_table)) / sum(classification_table)\n\n[1] 0.03524704\n\n\nQuestion 3\nAnd now calculate the Entropy \\(R^2\\).\n\nentropy &lt;- function(p) sum(-p * log(p))\n\nerror_prior &lt;- entropy(fit$P) # Class proportions\nerror_post &lt;- mean(apply(fit$posterior, 1, entropy))\n(R2_entropy  &lt;- (error_prior - error_post) / error_prior) # 0.741\n\n[1] 0.7410987\n\n\nIncluding covariates\nQuestion 4\nNow fit the four-class model, but include covariates that predict the class membership. Class membership is predicted by gender and a quadratic age effect.\nWe also use the results from the model without covariates as starting values for the solution.\nThis is where the analyzed data would have been different if we had not already deleted all cases with at least one missing value above using na.omit. In practice this may lead to trouble, especially when there are many variables.\n\nform_activism &lt;- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ \n  gndr + agea + I(agea^2)\n\ness_greece_poly &lt;- ess_greece %&gt;% \n  mutate(agea = scale(agea))\n\nfit_covariates &lt;-  \n  poLCA(form_activism, \n        data = ess_greece_poly, nclass = 4, \n        probs.start = fit$probs, \n        verbose = FALSE, nrep = 50, maxiter = 3e3)\n\nQuestion 5\nConfirm that the results now include a multinomial regression coefficients in a model predicting class membership.\n\nfit_covariates\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$contplt\n           Pr(1)  Pr(2)\nclass 1:  0.2460 0.7540\nclass 2:  0.7566 0.2434\nclass 3:  0.7619 0.2381\nclass 4:  0.0514 0.9486\n\n$wrkprty\n           Pr(1)  Pr(2)\nclass 1:  0.1066 0.8934\nclass 2:  0.9426 0.0574\nclass 3:  0.5423 0.4577\nclass 4:  0.0004 0.9996\n\n$wrkorg\n           Pr(1)  Pr(2)\nclass 1:  0.2283 0.7717\nclass 2:  1.0000 0.0000\nclass 3:  0.1618 0.8382\nclass 4:  0.0062 0.9938\n\n$badge\n           Pr(1)  Pr(2)\nclass 1:  0.1008 0.8992\nclass 2:  0.8711 0.1289\nclass 3:  0.3687 0.6313\nclass 4:  0.0000 1.0000\n\n$sgnptit\n           Pr(1)  Pr(2)\nclass 1:  0.5029 0.4971\nclass 2:  0.8243 0.1757\nclass 3:  0.0027 0.9973\nclass 4:  0.0056 0.9944\n\n$pbldmn\n           Pr(1)  Pr(2)\nclass 1:  0.3951 0.6049\nclass 2:  0.8277 0.1723\nclass 3:  0.2251 0.7749\nclass 4:  0.0158 0.9842\n\n$bctprd\n           Pr(1)  Pr(2)\nclass 1:  0.7298 0.2702\nclass 2:  0.6846 0.3154\nclass 3:  0.2121 0.7879\nclass 4:  0.0983 0.9017\n\nEstimated class population shares \n 0.0653 0.0117 0.0387 0.8843 \n \nPredicted class memberships (by modal posterior prob.) \n 0.049 0.0116 0.033 0.9064 \n \n========================================================= \nFit for 4 latent classes: \n========================================================= \n2 / 1 \n            Coefficient  Std. error  t value  Pr(&gt;|t|)\n(Intercept)    -1.20234     0.88172   -1.364     0.176\ngndr           -0.45999     0.55026   -0.836     0.405\nagea           -0.40722     0.48011   -0.848     0.399\nI(agea^2)      -0.00799     0.42691   -0.019     0.985\n========================================================= \n3 / 1 \n            Coefficient  Std. error  t value  Pr(&gt;|t|)\n(Intercept)    -0.24986     0.68744   -0.363     0.717\ngndr           -0.30756     0.40474   -0.760     0.449\nagea            0.51671     0.23895    2.162     0.033\nI(agea^2)       0.22320     0.19886    1.122     0.265\n========================================================= \n4 / 1 \n            Coefficient  Std. error  t value  Pr(&gt;|t|)\n(Intercept)     1.97587     0.40630    4.863     0.000\ngndr            0.26953     0.24745    1.089     0.279\nagea            0.27742     0.14518    1.911     0.059\nI(agea^2)       0.29597     0.13349    2.217     0.029\n========================================================= \nnumber of observations: 2062 \nnumber of estimated parameters: 40 \nresidual degrees of freedom: 87 \nmaximum log-likelihood: -2764.565 \n \nAIC(4): 5609.129\nBIC(4): 5834.387\nX^2(4): 126.1331 (Chi-square goodness of fit) \n \nALERT: estimation algorithm automatically restarted with new initial values \n \n\n\nQuestion 6\nCheck if the solution has changed now that covariates are included.\n\ntidy(fit_covariates) %&gt;% \n  filter(outcome == 2) %&gt;% \n  mutate(class = as.factor(class)) %&gt;%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\nQuestion 7\nPlot the results of the multinomial model\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Extract posterior probabilities of each class\nposterior_df &lt;- as.data.frame(fit_covariates$posterior)\n\n# Add covariates to the dataset\nposterior_df &lt;- ess_greece_poly %&gt;%\n  dplyr::select(gndr, agea) %&gt;%\n  bind_cols(posterior_df)\n\n# Rename class probability columns\ncolnames(posterior_df)[3:ncol(posterior_df)] &lt;- paste0(\"Class_\", 1:4)\n\n# Convert gender to factor for plotting\nposterior_df$gndr &lt;- as.factor(posterior_df$gndr)\n\n\n# Reshape data to long format for ggplot\nposterior_long &lt;- posterior_df %&gt;%\n  pivot_longer(cols = starts_with(\"Class_\"), \n               names_to = \"Class\", values_to = \"Probability\")\n\n# Plot probability of class membership as a function of age\nggplot(posterior_long, aes(x = agea, y = Probability, color = Class)) +\n  geom_smooth(method = \"loess\", se = TRUE) +\n  labs(title = \"Effect of Age on Class Membership\",\n       x = \"Age\", y = \"Probability of Class Membership\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nggplot(posterior_long, aes(x = gndr, y = Probability, fill = Class)) +\n  geom_bar(stat = \"summary\", fun = \"mean\", position = \"dodge\") +\n  labs(title = \"Effect of Gender on Class Membership\",\n       x = \"Gender\", y = \"Mean Probability of Class Membership\") +\n  theme_minimal()"
  },
  {
    "objectID": "Labs/Day_2/Lab_3/8_Lab.html",
    "href": "Labs/Day_2/Lab_3/8_Lab.html",
    "title": "EM: categorical indicators",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of conditionally independent binary indicators, and to estimate that mixture (LCA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job. You can copy code into your R environment by clicking the copy icon in the top right of each code block."
  },
  {
    "objectID": "Labs/Day_2/Lab_3/8_Lab.html#em-for-categorical-indicators",
    "href": "Labs/Day_2/Lab_3/8_Lab.html#em-for-categorical-indicators",
    "title": "EM: categorical indicators",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of conditionally independent binary indicators, and to estimate that mixture (LCA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job. You can copy code into your R environment by clicking the copy icon in the top right of each code block."
  },
  {
    "objectID": "Labs/Day_2/Lab_3/8_Lab.html#exercises",
    "href": "Labs/Day_2/Lab_3/8_Lab.html#exercises",
    "title": "EM: categorical indicators",
    "section": "Exercises",
    "text": "Exercises\nQuestion 1\n\nset.seed(202303)\n\nn &lt;- 1000L # Sample size\n\nP_X_true &lt;- 0.4 # True pi (will be class size of X=2)\n\n# Sample class memberships:\nX &lt;- sample(1:2, size = n, replace = TRUE, \n            prob = c(1 - P_X_true, P_X_true))\n\n# True profiles:\nP_Y.X_true &lt;- list(\n  Y1 = matrix(c(0.9, 0.2,\n                0.1, 0.8), byrow = TRUE, nrow = 2),\n  Y2 = matrix(c(0.7, 0.2,\n                0.3, 0.8), byrow = TRUE, nrow = 2),\n  Y3 = matrix(c(0.95, 0.4,\n                0.05, 0.6), byrow = TRUE, nrow = 2)\n)\n\nThe conditional (profile) probabilities \\(P(Y_j | X)\\) are:\n\nprint(P_Y.X_true)\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nWe now sample some data using the conditional probabilities and the values of X.\n\n# Sample observed indicators from binomials (Bernoullis):\nY1 &lt;- rbinom(n, size = 1, prob = P_Y.X_true[[1]][2, X])\nY2 &lt;- rbinom(n, size = 1, prob = P_Y.X_true[[2]][2, X])\nY3 &lt;- rbinom(n, size = 1, prob = P_Y.X_true[[3]][2, X])\n\ndf_samp &lt;- data.frame(Y1, Y2, Y3) # For other analyses\n\nRead the simulation code above. Can you explain in your own words what happens here? Do you have any questions about it?\nQuestion 2\nWe will take as parameters the probabilities of a “1” response on each of the three indicators, given \\(X=1\\) or \\(X=2\\), respectively. And of course the class size \\(\\pi = P(X = 2)\\). So there are 7 parameters in total. Since there are \\(2^3 = 8\\) observeed patterns, but only 7 independent ones, the degrees of freedom for this model equals zero.\n\n# As usual, we start by guessing parameter values\nguess_PY.X &lt;- list(\n  Y1 = c(0.4, 0.6),\n  Y2 = c(0.4, 0.6),\n  Y3 = c(0.4, 0.6)\n)\n# We will take PX (pi) to be P(X = 2)\nguess_PX &lt;- 0.5\n\n# Number of EM iterations\nmaxiter &lt;- 15\n\n# Start the EM algorithm!\nfor(it in 1:maxiter) {\n  # Just some output \n  if(it == 1) # A trick to make Quarto output this line correctly\n    cat(\"It:\\t(X=2)\\tY1|X=1\\tY1|X=2\\tY2|X=1\\tY2|X=2\\tY3|X=1\\tY3|X=2\\n\")\n  cat(sprintf(\"%03d\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\n\", it,\n      guess_PX, \n      guess_PY.X$Y1[1], guess_PY.X$Y1[2],\n      guess_PY.X$Y2[1], guess_PY.X$Y2[2],\n      guess_PY.X$Y3[1], guess_PY.X$Y3[2]))\n\n  # E-step\n  # ------------------\n  # For clarity purposes I am not using a loop over the three variables. \n  #  In practice, you will probably want to do that. \n\n  # The probability of observing that value if X were X=1 or X=2\n  \n  # Here we use the assumption that each value is ~ Bernoulli\n  #. In practice you would work with logs, but here we ignore that\n  P_Y1.X1 &lt;- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[1])\n  P_Y1.X2 &lt;- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[2])\n  \n  P_Y2.X1 &lt;- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[1])\n  P_Y2.X2 &lt;- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[2])\n  \n  P_Y3.X1 &lt;- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[1])\n  P_Y3.X2 &lt;- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[2])\n  \n  # Now we use the conditional independence assumption \n  #.  to get the probability of the whole pattern (df_samp[i, ])\n  # (In practice you will want to takes a sum of logs instead)\n  P_Y_X1 &lt;-  P_Y1.X1 * P_Y2.X1 * P_Y3.X1\n  P_Y_X2 &lt;-  P_Y1.X2 * P_Y2.X2 * P_Y3.X2\n  \n  # Now we use the mixture assumption to get the marginal probability of the pattern:\n  P_Y &lt;- (1 - guess_PX)*P_Y_X1 + guess_PX*P_Y_X2\n  \n  # Finally we are ready to apply Bayes rule to get the posterior \n  #. P(X = 2 | Y = y)\n  post_X2 &lt;- guess_PX*P_Y_X2 / P_Y\n  \n  # M-step \n  # ------------------\n  # Now we have the posterior it is easy to calculate the probabilities we need\n  \n  # M-step for 'priors' / class size of X=2\n  guess_PX &lt;- mean(post_X2)\n  \n  # M-step for profiles\n  guess_PY.X$Y1[1] &lt;- weighted.mean(Y1, w = (1 - post_X2))\n  guess_PY.X$Y1[2] &lt;- weighted.mean(Y1, w = post_X2)\n  \n  guess_PY.X$Y2[1] &lt;- weighted.mean(Y2, w = (1 - post_X2))\n  guess_PY.X$Y2[2] &lt;- weighted.mean(Y2, w = post_X2)\n  \n  guess_PY.X$Y3[1] &lt;- weighted.mean(Y3, w = (1 - post_X2))\n  guess_PY.X$Y3[2] &lt;- weighted.mean(Y3, w = post_X2)\n}\n\nIt: (X=2)   Y1|X=1  Y1|X=2  Y2|X=1  Y2|X=2  Y3|X=1  Y3|X=2\n001 0.500   0.400   0.600   0.400   0.600   0.400   0.600\n002 0.426   0.228   0.538   0.341   0.647   0.145   0.420\n003 0.423   0.167   0.623   0.289   0.720   0.092   0.495\n004 0.415   0.125   0.692   0.256   0.775   0.057   0.552\n005 0.406   0.106   0.732   0.247   0.798   0.042   0.584\n006 0.399   0.099   0.753   0.250   0.804   0.037   0.601\n007 0.393   0.098   0.765   0.255   0.804   0.036   0.611\n008 0.389   0.098   0.773   0.259   0.804   0.035   0.618\n009 0.385   0.099   0.778   0.262   0.805   0.036   0.624\n010 0.381   0.100   0.782   0.264   0.806   0.037   0.628\n011 0.378   0.101   0.785   0.266   0.808   0.037   0.631\n012 0.376   0.102   0.788   0.267   0.810   0.038   0.633\n013 0.374   0.103   0.790   0.268   0.811   0.039   0.636\n014 0.371   0.105   0.792   0.269   0.813   0.040   0.638\n015 0.370   0.106   0.794   0.270   0.814   0.041   0.640\n\n\nRead the EM loop. Do you understand all steps?\nQuestion 3\n\nguess_PY.X |&gt; \n  lapply(function(x) rbind(1-x, x)) |&gt;\n  print(digits = 3)\n\n$Y1\n   [,1]  [,2]\n  0.894 0.204\nx 0.106 0.796\n\n$Y2\n  [,1]  [,2]\n  0.73 0.184\nx 0.27 0.816\n\n$Y3\n    [,1]  [,2]\n  0.9588 0.359\nx 0.0412 0.641\n\n\nInterpret the resulting estimates of the conditional probabilities (profiles) as printed by the code above.\nQuestion 4\nCompare these to the true profiles, which were:\n\nP_Y.X_true\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nQuestion 5\nThe estimated class sizes are\n\nc(1 - guess_PX, guess_PX) |&gt; \n  print(digits = 3)\n\n[1] 0.632 0.368\n\n\nCompare these to the “priors” (class sizes), which were:\n\nc(1 - P_X_true, P_X_true) |&gt; \n  print(digits = 3)\n\n[1] 0.6 0.4\n\n\nQuestion 6\nCode understanding check:\n\na. In the simulation code, explain why the subscripts 1 and 2 are used respectively in P_Y.X_true[[1]][2, X].\nb. Which values would you change if you wanted to implement random starts?\nc. Suppose the model said that the variables do not come from a binomial (Bernoulli) distribution, but from some other distribution (for example a Beta one). Which lines would you need to change?\n\nQuestion 7\nTry reversing the starting values, so, Y1 = c(0.4, 0.6) becomes Y1 = c(0.6, 0.4), and similarly for the other two variables. What happens to the estimates? How do these compare to the true values now?\nQuestion 8\nSet the number of iterations of the EM algorithm to a large number, such as maxiter = 200. What happens to the estimates?\nQuestion 9\nTry out different values of the prior, the profile probabilities, and the sample size. Report any interesting observations.\nQuestion 10\nFit the same model using poLCA (or otherwise). (Remember that you can directly analyze df_samp.) Do the results agree with our own EM implementation?\nQuestion 11\nBONUS: Calculate the log-likelihood of the model.\nQuestion 12\nBONUS: Investigate the entropy \\(R^2\\) of the posterior classification as a function of (a) the profile probabilities and (b) prior."
  },
  {
    "objectID": "Extra/Day_2/Exercise_2/9_Exercise.html",
    "href": "Extra/Day_2/Exercise_2/9_Exercise.html",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "",
    "text": "In this project, you will work on reading and reproducing the following paper:\n  Beller, J. (2021). Morbidity profiles in Europe and Israel: International comparisons\n          from 20 countries using biopsychosocial indicators of health via latent class analysis.\n          Journal of Public Health. https://doi.org/10.1007/s10389-021-01673-0\nYou can download a copy of the paper here: https://daob.nl/files/lca/beller-2021.pdf\nThe data used in this study were from the European Social Survey, round 7 (2014). You can find these (and more recent) data here: https://www.europeansocialsurvey.org/data/. You will need to register to download the data. Registration is free and should be instantaneous."
  },
  {
    "objectID": "Extra/Day_2/Exercise_2/9_Exercise.html#reproducing-a-published-lca",
    "href": "Extra/Day_2/Exercise_2/9_Exercise.html#reproducing-a-published-lca",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "",
    "text": "In this project, you will work on reading and reproducing the following paper:\n  Beller, J. (2021). Morbidity profiles in Europe and Israel: International comparisons\n          from 20 countries using biopsychosocial indicators of health via latent class analysis.\n          Journal of Public Health. https://doi.org/10.1007/s10389-021-01673-0\nYou can download a copy of the paper here: https://daob.nl/files/lca/beller-2021.pdf\nThe data used in this study were from the European Social Survey, round 7 (2014). You can find these (and more recent) data here: https://www.europeansocialsurvey.org/data/. You will need to register to download the data. Registration is free and should be instantaneous."
  },
  {
    "objectID": "Extra/Day_2/Exercise_2/9_Exercise.html#assignment",
    "href": "Extra/Day_2/Exercise_2/9_Exercise.html#assignment",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "Assignment",
    "text": "Assignment\nQuestion 1\nObtain the data\nQuestion 2\nCreate the dataset as indicated in the article. You should end up with 16 indicators, (excluding any covariates such as country, age, gender, or education)\n\na. Which steps taken in the paper could you criticize? Do you think they will have a large impact on the final conclusions?\nb. Create two different versions of the data, one of which is as close as possible to the paper, the other differing only on the aspect of data wrangling that you believe will be the most influential.\nc. Create a smaller dataset, selecting only one country of your choice. You will use this smaller dataset to initially debug the subsequent analyses. From the list of covariates in table 4, select a maximum of two or three that you find of interest.\nd. For each recode, double-check your recode by creating a before/after cross-table, or by calculating means within categories for dichotomized variables. Did everything go according to your plan?\ne. Perform a sanity check on your data. Pay attention to Roger Peng’s EDA advice:\ni. Read in your data : Are the names of the variables correct, concise, and unambiguous?\nii. Check the packaging : Are the number of rows and columns as expected? Are the types of your variables as expected? Do your variables contain weird values (such as -99)? Are some variables all-missing or constant?\niii. Look at the top and the bottom of your data : use head() and tail() or some other method to check the top and bottom.\niv. Check your “n”s : do the sample sizes correspond to the documentation? To the paper?\nv. Validate with at least one external data source : check descriptives of your data against those in the paper (small differences may occur). Are distributions of study variables (e.g. depression) and background variables (e.g. age, gender, education) plausible? (you may want to look at official statistics for your chosen country)\nvi. Make a plot, look at descriptives : you are free to make sensible choices of “checks” here. Examples could include checking that correlations between closely related variables are not negative, scatterplots of continuous variables or dotplots/boxplots of continuous/categorical variabels to check for outliers, etc.\n\nQuestion 3\nUse poLCA to estimate the LCA with 1, 2, 3, 4, 5, and 6 classes on your small dataset. (hint: it is always a good idea to start off with a small number of indicators to check that things are going OK, before increasing the model size)\n\na. Check: Did you specify everything correctly?\nb. Do a sanity check on the results. Pay attention to: i. Reported sample sizes ii. Unexpected direction of associations iii. Forgotten indicators, or inadvertently included covariates as indicators\nc. Rerun your analysis with multiple random starts, and compare the best log-likelihood, ensuring your solution did not end up in a local maximum\nd. Model evaluation:\ni. Compare loglikelihood, BIC and AIC among the 6 models. Use a scree plot to select the number of classes.\nii. Look at bivariate residuals (BVRs). Are there any local dependencies? Is it better to increase the number of classes, or fit a model with fewer classes but local dependence?\niii. (BONUS) Perform a parametric bootstrap-likelihood ration test of your selected model. (hint: package flexmix allows parametric bootstrapping of the LRT via the function LR_test.)\ne. Model interpretation:\ni. Look at probability profiles. Without looking at the Beller (2021) paper, create a description for yourself of the profiles you have created.\nii. Create a table of the estimated class sizes. Are any classes too small to be of interest?\niii. Create a classification table and calculate the entropy \\(R^2\\). Which classes are well-separated?\niv. Look at the results for the prediction of class membership from covariates. Are the effects in the expected direction? What are the confidence intervals of the parameter estimates?\n(BONUS:) Create a plot of each covariate versus the probability to belong to each class.\n\nQuestion 4\nRepeat the analysis and interpretation steps with a larger model, using all countries.\nQuestion 5\nCompare the results from your two datasets from part 2(c) above.\nQuestion 6\nHow does your analysis compare to the results in Beller (2021)? Go through each of the steps in the previous question and report any similarities/differences.\nQuestion 7\nWhat do you conclude about profiles of health status in the ESS?\nQuestion 8\nBONUS: Bootstrap (empirically) the standard errors of the model and compare with the standard se’s given in poCLA (hint: packages flexmix and BayesLCA allow bootstrapping. To get bootstrap se’s using blca, use argument method = “em”, and blca.boot\nQuestion 9\nBONUS: Do the analysis with a newer ESS dataset and compare the results."
  },
  {
    "objectID": "Extra/Day_2/Exercise_1/5_Exercise.html",
    "href": "Extra/Day_2/Exercise_1/5_Exercise.html",
    "title": "Exercise: Attitudes towards climate change in Europe",
    "section": "",
    "text": "You can use code snippets from the earlier labs to help answer the questions of this exercise. In addition, there is some example code on the bottom of this document that could help you as well.\nQuestion 1\nRead in the ESS round 10 (2020) climate change attitudes data.\nAn easy to read codebook copied from ESS is here: https://daob.nl/files/lca/ESS10-codebook.html. The full documentation is here: https://ess-search.nsd.no/en/study/172ac431-2a06-41df-9dab-c1fd8f3877e7.\n\n\nccnthum - Climate change caused by natural processes, human activity, or both\n\nccrdprs - To what extent feel personal responsibility to reduce climate change\n\nwrclmch - How worried about climate change\n\ntestic37 - Imagine large numbers of people limit energy use, how likely reduce climate change\n\ntestic38 - How likely, large numbers of people limit energy use\n\ntestic39 - How likely, governments in enough countries take action to reduce climate change\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\neisced - Highest level of education, ES - ISCED\n\n\nNote: The data have been preprocessed by ruthlessly subjecting them to na.omit. I have also recoded eisced to be missing except for values 1-7. Otherwise, the data are as-is from the ESS website.\nQuestion 2\nIn order not to spend most of your precious time waiting, filter the data to only include one country of your choice.\nQuestion 3\nPerform any exploratory data analyses you find necessary.\nQuestion 4\nUsing poLCA, fit LCA models in which the seven participation items are used as indicators (so, exclude agea, gndr, and eisced from the analysis for now). Try models with a different number of classes. Advice: try 1–6.\nQuestion 5\nUse appropriate global fit measures, or any other criteria you prefer, to select the number of classes. Explain your choice.\nQuestion 6\nLook at local fit measures to assess the fit of your selected model.\nQuestion 7\nCreate a profile plot for your selected model. (Hint: You can use the adjusted plotting code below.)\nQuestion 8\nInterpret your selected model by looking at the profiles. How would you label the classes?\nQuestion 9\nCreate a classification table.\nQuestion 10\nCalculate the classification error and entropy \\(R^2\\).\nQuestion 11\nRefit your selected model, now while predicting class membership from agea, the square of agea, gndr, and eisced.\nQuestion 12\nPlot the probability of each class as a function of agea, gndr, and eisced, according to your model. What do you conclude?\nQuestion 13\nBONUS: Investigate the distribution of classes over countries by redoing the analyses using all countries in the ess dataset\nQuestion 14\nBONUS: Deal more appropriately with missing data, for example by using mice. You will need the original data from ESS.\n\nUseful libraries\n\nset.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom) \nlibrary(haven)\nlibrary(poLCA)\n\nRead the data from the European Social Survey, round 10 (2020).\n\ness10_climate &lt;- read_csv(\"https://daob.nl/files/lca/ess10_climate.csv.gz\") \n\ness10_climate |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n\nCode to create a subset and fit a model\n\ness10_climate_it &lt;- filter(ess10_climate, cntry == \"IT\")\ness10_climate_it$ccrdprs &lt;- ess10_climate_it$ccrdprs + 1\n\nfit &lt;- poLCA(cbind(ccnthum, ccrdprs , wrclmch , \n                     testic37, testic38, testic39) ~ \n                 agea + I(agea^2) + gndr + eisced, \n                data = ess10_climate_it, nclass = 3, \n                maxiter = 2e3, nrep=10, verbose = FALSE)\n\nCode to create the profile plot (note that the assignment here differs from the lab)\n\ntidy(fit) %&gt;% # from `broom` package\n    mutate(class = as.factor(class), outcome = as.factor(outcome)) %&gt;%\n    ggplot(aes(outcome, estimate, group = class, color = class)) +\n    geom_point() + geom_line() + facet_wrap(~variable, scales = \"free_x\")+\n    geom_errorbar(aes(ymin = estimate - 2*std.error, \n                      ymax = estimate + 2*std.error), width = 0.2) +\n    theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nUnfortunately, effects does not appear to function properly for this type of model. The code below could be helpful to create effects plots by hand. It assumes that the right-hand side of formula used was agea + I(agea^2) + gndr + eisced.\nThe code below creates a dataframe with the “effects” of the various covariates based on the model estimates from fit. This is also how effects works and demonstrated within the poLCA help file.\n\n# Extract posterior probabilities of each class\nposterior_df &lt;- as.data.frame(fit$posterior)\n\n# Add covariates to the dataset\nposterior_df &lt;- ess10_climate_it %&gt;%\n  dplyr::select(agea) %&gt;%\n  bind_cols(posterior_df)\n\n# Rename class probability columns\ncolnames(posterior_df)[2:ncol(posterior_df)] &lt;- paste0(\"Class_\", 1:3)\n\n# Reshape data to long format for ggplot\nposterior_long &lt;- posterior_df %&gt;%\n  pivot_longer(cols = starts_with(\"Class_\"), \n               names_to = \"Class\", values_to = \"Probability\")\n\n# Plot probability of class membership as a function of age\nggplot(posterior_long, aes(x = agea, y = Probability, color = Class)) +\n  geom_smooth(method = \"loess\", se = TRUE) +\n  labs(title = \"Effect of Age on Class Membership\",\n       x = \"Age\", y = \"Probability of Class Membership\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Extra/Day_2/Exercise_1/5_Exercise.html#exercise-attitudes-towards-climate-change-in-europe",
    "href": "Extra/Day_2/Exercise_1/5_Exercise.html#exercise-attitudes-towards-climate-change-in-europe",
    "title": "Exercise: Attitudes towards climate change in Europe",
    "section": "",
    "text": "You can use code snippets from the earlier labs to help answer the questions of this exercise. In addition, there is some example code on the bottom of this document that could help you as well.\nQuestion 1\nRead in the ESS round 10 (2020) climate change attitudes data.\nAn easy to read codebook copied from ESS is here: https://daob.nl/files/lca/ESS10-codebook.html. The full documentation is here: https://ess-search.nsd.no/en/study/172ac431-2a06-41df-9dab-c1fd8f3877e7.\n\n\nccnthum - Climate change caused by natural processes, human activity, or both\n\nccrdprs - To what extent feel personal responsibility to reduce climate change\n\nwrclmch - How worried about climate change\n\ntestic37 - Imagine large numbers of people limit energy use, how likely reduce climate change\n\ntestic38 - How likely, large numbers of people limit energy use\n\ntestic39 - How likely, governments in enough countries take action to reduce climate change\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\neisced - Highest level of education, ES - ISCED\n\n\nNote: The data have been preprocessed by ruthlessly subjecting them to na.omit. I have also recoded eisced to be missing except for values 1-7. Otherwise, the data are as-is from the ESS website.\nQuestion 2\nIn order not to spend most of your precious time waiting, filter the data to only include one country of your choice.\nQuestion 3\nPerform any exploratory data analyses you find necessary.\nQuestion 4\nUsing poLCA, fit LCA models in which the seven participation items are used as indicators (so, exclude agea, gndr, and eisced from the analysis for now). Try models with a different number of classes. Advice: try 1–6.\nQuestion 5\nUse appropriate global fit measures, or any other criteria you prefer, to select the number of classes. Explain your choice.\nQuestion 6\nLook at local fit measures to assess the fit of your selected model.\nQuestion 7\nCreate a profile plot for your selected model. (Hint: You can use the adjusted plotting code below.)\nQuestion 8\nInterpret your selected model by looking at the profiles. How would you label the classes?\nQuestion 9\nCreate a classification table.\nQuestion 10\nCalculate the classification error and entropy \\(R^2\\).\nQuestion 11\nRefit your selected model, now while predicting class membership from agea, the square of agea, gndr, and eisced.\nQuestion 12\nPlot the probability of each class as a function of agea, gndr, and eisced, according to your model. What do you conclude?\nQuestion 13\nBONUS: Investigate the distribution of classes over countries by redoing the analyses using all countries in the ess dataset\nQuestion 14\nBONUS: Deal more appropriately with missing data, for example by using mice. You will need the original data from ESS.\n\nUseful libraries\n\nset.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom) \nlibrary(haven)\nlibrary(poLCA)\n\nRead the data from the European Social Survey, round 10 (2020).\n\ness10_climate &lt;- read_csv(\"https://daob.nl/files/lca/ess10_climate.csv.gz\") \n\ness10_climate |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n\nCode to create a subset and fit a model\n\ness10_climate_it &lt;- filter(ess10_climate, cntry == \"IT\")\ness10_climate_it$ccrdprs &lt;- ess10_climate_it$ccrdprs + 1\n\nfit &lt;- poLCA(cbind(ccnthum, ccrdprs , wrclmch , \n                     testic37, testic38, testic39) ~ \n                 agea + I(agea^2) + gndr + eisced, \n                data = ess10_climate_it, nclass = 3, \n                maxiter = 2e3, nrep=10, verbose = FALSE)\n\nCode to create the profile plot (note that the assignment here differs from the lab)\n\ntidy(fit) %&gt;% # from `broom` package\n    mutate(class = as.factor(class), outcome = as.factor(outcome)) %&gt;%\n    ggplot(aes(outcome, estimate, group = class, color = class)) +\n    geom_point() + geom_line() + facet_wrap(~variable, scales = \"free_x\")+\n    geom_errorbar(aes(ymin = estimate - 2*std.error, \n                      ymax = estimate + 2*std.error), width = 0.2) +\n    theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nUnfortunately, effects does not appear to function properly for this type of model. The code below could be helpful to create effects plots by hand. It assumes that the right-hand side of formula used was agea + I(agea^2) + gndr + eisced.\nThe code below creates a dataframe with the “effects” of the various covariates based on the model estimates from fit. This is also how effects works and demonstrated within the poLCA help file.\n\n# Extract posterior probabilities of each class\nposterior_df &lt;- as.data.frame(fit$posterior)\n\n# Add covariates to the dataset\nposterior_df &lt;- ess10_climate_it %&gt;%\n  dplyr::select(agea) %&gt;%\n  bind_cols(posterior_df)\n\n# Rename class probability columns\ncolnames(posterior_df)[2:ncol(posterior_df)] &lt;- paste0(\"Class_\", 1:3)\n\n# Reshape data to long format for ggplot\nposterior_long &lt;- posterior_df %&gt;%\n  pivot_longer(cols = starts_with(\"Class_\"), \n               names_to = \"Class\", values_to = \"Probability\")\n\n# Plot probability of class membership as a function of age\nggplot(posterior_long, aes(x = agea, y = Probability, color = Class)) +\n  geom_smooth(method = \"loess\", se = TRUE) +\n  labs(title = \"Effect of Age on Class Membership\",\n       x = \"Age\", y = \"Probability of Class Membership\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "index.html#day-3",
    "href": "index.html#day-3",
    "title": "Course Material Latent Class Analysis",
    "section": "Day 3",
    "text": "Day 3\n\n\n\nTopic\nLecture\nLab\nExtra material\n\n\n\n\nLatent GOLD\nLecture Latent GOLD\nLab Latent GOLD\nDataset heinen2\n\n\nLocal dependence models and multiple latent variables\nLecture dependence models and multiple LVs\nLab local dependence models\nLab multiple LVs\nDataset uebersax\nDataset vote\nDataset political\n\n\nOrdinal variables and 3-step modelling\nLecture ordinal variables and 3-step modelling\nLab ordinal variables and 3-step modelling\nDataset gss82\n\n\n\nThe materials for this course were originally developed in 2023 by Daniel Oberski. You can find this version of the course on his page: https://daob.github.io/latent-class-analysis/."
  },
  {
    "objectID": "Labs/Day_3/2_LAB_introLG.html",
    "href": "Labs/Day_3/2_LAB_introLG.html",
    "title": "Lab part 1: Political activism in Greece",
    "section": "",
    "text": "For this lab, we work with the Heinen (1996) dataset. This dataset consists of five dichotomous indicators on gender roles. The sample we use only contains males. The indicators correspond to the following questions:\n\nAGA_MEN: A man should be the primary provider for his family (1=agree, 0=disagree)\nNO_JOB: A woman’s primary responsibility should be taking care of the home and children (1=agree, 0=disagree)\nMAN_BRE: Men should have the final say in important family decisions (1=agree, 0=disagree)\nNO_EDUC: It is better if women stay at home rather than pursuing education or work (1=agree, 0=disagree)\nRAISECHI: Men and women should share responsibilities equally in a relationship (1=agree, 0=disagree)\n\nQuestion 1\nOpen the dataset with Latent GOLD and run a 1, 2, 3 and 4 class model through the GUI.\nQuestion 2\nInterpret the fit of these models. Which model do you conclude fits best?\nQuestion 3\nWhat is the entropy \\(R^2\\) value of your selected model? Can you interpret this value?\nQuestion 4\nProvide a substantive interpretation of the latent classes.\nQuestion 5\nWhat is the probability of \\((Y_{AGA\\_MEN}=1)|X=1)\\)? Can you provide a substantive interpetation for this value?\nQuestion 6 Generate the syntax of your model by clicking on the button create syntax. Which part of the syntax allows you to specify the latent class model?\nQuestion 7 How do you specify the number of latent classes?\nQuestion 8 In the syntax, can you find the specifications of the EM algorithm? Based on the syntax, can you explain how EM is implemented in Latent GOLD?"
  },
  {
    "objectID": "Labs/Day_3/Lab1/2_LAB_introLG.html",
    "href": "Labs/Day_3/Lab1/2_LAB_introLG.html",
    "title": "Lab part 1: Political activism in Greece",
    "section": "",
    "text": "For this lab, we work with the Heinen (1996) dataset. This dataset consists of five dichotomous indicators on gender roles. The sample we use only contains males. The indicators correspond to the following questions:\n\nAGA_MEN: A man should be the primary provider for his family (1=agree, 0=disagree)\nNO_JOB: A woman’s primary responsibility should be taking care of the home and children (1=agree, 0=disagree)\nMAN_BRE: Men should have the final say in important family decisions (1=agree, 0=disagree)\nNO_EDUC: It is better if women stay at home rather than pursuing education or work (1=agree, 0=disagree)\nRAISECHI: Men and women should share responsibilities equally in a relationship (1=agree, 0=disagree)\n\nQuestion 1\nOpen the dataset with Latent GOLD and run a 1, 2, 3 and 4 class model through the GUI.\nQuestion 2\nInterpret the fit of these models. Which model do you conclude fits best?\nQuestion 3\nWhat is the entropy \\(R^2\\) value of your selected model? Can you interpret this value?\nQuestion 4\nProvide a substantive interpretation of the latent classes.\nQuestion 5\nWhat is the probability of \\((Y_{AGA\\_MEN}=1)|X=1)\\)? Can you provide a substantive interpetation for this value?\nQuestion 6 Generate the syntax of your model by clicking on the button create syntax. Which part of the syntax allows you to specify the latent class model?\nQuestion 7 How do you specify the number of latent classes?\nQuestion 8 In the syntax, can you find the specifications of the EM algorithm? Based on the syntax, can you explain how EM is implemented in Latent GOLD?"
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_dependency.html",
    "href": "Labs/Day_3/Lab2/4_Lab_dependency.html",
    "title": "Local dependence LCA in R",
    "section": "",
    "text": "The standard latent class “cluster” model specifies that the indicators \\(Y_1, Y_2, \\ldots, Y_p\\) should be conditionally independent, given the latent variable \\(X\\), say, \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = \\prod_{j = 1}^p P(Y_j | X).\n\\] The product on the right-hand side indicates this conditional independence.\nFor example, suppose four diagnostic tests \\(Y_j\\), for \\(j = 1, \\ldots, p = 4\\), have been used to test for a disease \\(X \\in \\{0, 1\\}\\). Then for all people within the “healthy” class (\\(X=0\\), say), the four diagnostic tests should be like four independent biased coin flips, and the same should apply in the “diseased” class. This would be violated, for instance, when on diagnostic test depends on the results of another (e.g. the results of one are used to determine another), or when two tests use the same biological technique, thus giving similar errors. The same concern can be found in the SEM literature under the term “error correlation”.\nLocal dependence is a violation of the assumptions. Instead of the model given above, if, say, indicators \\(Y_1\\) and \\(Y_2\\) are locally dependent, we cannot use the simple form given on the right-hand side in that equation, and we are forced to write \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = P(Y_1, Y_2 | X) \\prod_{j = 3}^p P(Y_j | X),\n\\] so we have to have a separate model for the conditional “cross-table” \\(P(Y_1, Y_2 | X)\\). Ignoring this can have consequences for the solution and your subsequent conclusions. In the first, locally independent, equation above, the sensitivity (\\(P(Y_j = 1 | X = 1)\\)) and specificity (\\(P(Y_j = 0 | X = 0)\\)) of two indicators will look high to the model if the indicators are strongly dependent. But when this dependence was due to an error correlation, the sensitivity and specificity will be overestimated. In the extreme case, imagine including the same completely random coin flip under two different names, with two excellent indicators of the latent variable. The latent class model will then output the exact opposite of the truth: the coin flips will look reliable, while the excellent indicators will look worthless, as you can verify for yourself below.\n\nlibrary(poLCA)\nset.seed(202302)\n\n\nn &lt;- 2*50L # Ensure sample size is even\nsensitivity &lt;- 0.8\nspecificity &lt;- 0.9\n\ntrue_x &lt;- rep(1:2, each = n/2) # Create true classes\nprobs_indicators &lt;- c(1 - specificity, sensitivity)[true_x]\n\n# The following is a single completely useless noise variable\n# (adding 1 is necessary because poLCA expects Y ∈ {1,2})\ngarbage_coinflip &lt;- rbinom(n, 1, prob = 0.5) + 1\n\n# Here are two excellent indicators of true_x, both with Se=0.8, Sp=0.9\ngreat_indicator1 &lt;- rbinom(n, 1, prob = probs_indicators) + 1\ngreat_indicator2 &lt;- rbinom(n, 1, prob = probs_indicators) + 1\n\n# The data contain two completely worthless indicators, which \n#   are completely dependent (in fact they are identical)\n# and two excellent indicators, which do have some small amount of error\nmade_up_data &lt;- data.frame(noise1 = garbage_coinflip, \n                noise2 = garbage_coinflip, \n                good1 = great_indicator1, \n                good2 = great_indicator2)\n\n# Run the latent class model using poLCA\nfit_polca &lt;- poLCA(cbind(noise1, noise2, good1, good2) ~ 1, nclass = 2, data = made_up_data)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$noise1\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$noise2\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$good1\n           Pr(1)  Pr(2)\nclass 1:  0.5000 0.5000\nclass 2:  0.6042 0.3958\n\n$good2\n           Pr(1)  Pr(2)\nclass 1:  0.5192 0.4808\nclass 2:  0.5417 0.4583\n\nEstimated class population shares \n 0.52 0.48 \n \nPredicted class memberships (by modal posterior prob.) \n 0.52 0.48 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 100 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -206.6095 \n \nAIC(2): 431.2189\nBIC(2): 454.6655\nG^2(2): 44.2938 (Likelihood ratio/deviance statistic) \nX^2(2): 40.92018 (Chi-square goodness of fit) \n \n\n\n\nlibrary(flexmix)\nfit_fm_ld_direct &lt;- \n  flexmix(~1, data = made_up_data-1, \n          k = 2, \n          model = list(\n            FLXMCmvbinary(noise1 ~ 1),\n            FLXMRglmfix(formula = cbind(noise2, 1-noise2) ~ 1, \n                        nested = list(k = 2, formula = ~ noise1),\n                        family = \"binomial\"), \n            FLXMCmvbinary(good1 ~ 1),\n            FLXMCmvbinary(good2 ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\nCall:\nflexmix(formula = ~1, data = made_up_data - 1, k = 2, model = list(FLXMCmvbinary(noise1 ~ \n    1), FLXMRglmfix(formula = cbind(noise2, 1 - noise2) ~ 1, \n    nested = list(k = 2, formula = ~noise1), family = \"binomial\"), \n    FLXMCmvbinary(good1 ~ 1), FLXMCmvbinary(good2 ~ 1)))\n\n       prior size post&gt;0 ratio\nComp.1  0.55   55    100  0.55\nComp.2  0.45   45    100  0.45\n\n'log Lik.' -184.6463 (df=10)\nAIC: 389.2926   BIC: 415.3443 \n\nparameters(fit_fm_ld_direct)\n\n[[1]]\nComp.1.center Comp.2.center \n    0.5273048     0.4222115 \n\n[[2]]\n                    Comp.1    Comp.2\ncoef.noise1       53.13213  53.13213\ncoef.(Intercept) -26.56607 -26.56607\n\n[[3]]\nComp.1.center Comp.2.center \n  0.003545498   0.995397964 \n\n[[4]]\nComp.1.center Comp.2.center \n    0.1794210     0.8249772 \n\n\nAs you can see, according to LCA, the locally dependent random noise items are perfect, while the very good indicators are almost worthless – exactly opposite to the truth. If you were so inclined, you could play around with the following elements to see how results might change:\n\nsensitivity and specificity values (currently \\(\\text{Se}=0.8\\), \\(\\text{Sp}=0.9\\));\nnumber of “good” indicators (currently two);\nnumber of dependent noise items (currently two);\nthe amount of local dependence (currently perfect dependence).\n\nIncluding an additional class can model this dependence. You can verify this by changing nclass = 2 to nclass = 3 above to see how results change. This may be a satisfactory solution there is no strong substantive reason to prefer a specific number of classes. For example, when mixture modeling is used as a density estimation technique, or when the analysis is exploratory. But you may not want to increase the number of classes when the latent classes are intended to have some predefined meaning, as is the case for our diagnostic testing example. In that case, we would like the two classes to signify “no disease” and “disease”, while possibly accounting for any local dependence.\n\nData from Uebersax (2009), https://www.john-uebersax.com/stat/condep.htm. These are data on four diagnostic tests for human HIV virus (Table 1) reported by Alvord et al. (1988).\n\nlibrary(tidyverse)\n\n# https://www.john-uebersax.com/stat/condep.htm\n\nlibrary(readr)\n\n# Load the dataset\nuebersax &lt;- read_table(\"https://raw.githubusercontent.com/lauraboeschoten/LCA_GESIS/main/Extra/Day_3/uebersax.tab\")\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  A = col_double(),\n  B = col_double(),\n  C = col_double(),\n  D = col_double(),\n  Freq = col_double()\n)\n\nuebersax01 &lt;- uebersax %&gt;% \n  mutate(across(A:D, ~ ifelse(.x == 1, 0, 1)),  # Convert 1 → 0 and 2 → 1\n         Freq = as.integer(Freq))  # Ensure Freq is an integer\n\nfrequencies_to_fulldata &lt;- function(df_freq) {\n  df_freq %&gt;%\n    uncount(Freq)\n}\n  \nuebersax_fulldata &lt;- frequencies_to_fulldata(uebersax)\n\nas.data.frame(table(uebersax_fulldata))\n\n   A B C D Freq\n1  1 1 1 1  170\n2  2 1 1 1    4\n3  1 2 1 1    6\n4  2 2 1 1    1\n5  1 1 2 1    0\n6  2 1 2 1    0\n7  1 2 2 1    0\n8  2 2 2 1    0\n9  1 1 1 2   15\n10 2 1 1 2   17\n11 1 2 1 2    0\n12 2 2 1 2    4\n13 1 1 2 2    0\n14 2 1 2 2   83\n15 1 2 2 2    0\n16 2 2 2 2  128\n\n\n\n\nTest\nDescription\n\n\n\nA\nRadioimmunoassay of antigen ag121\n\n\nB\nRadioimmunoassay of HIV p24\n\n\nC\nRadioimmunoassay of HIV gp120\n\n\nD\nEnzyme-linked immunosorbent assay\n\n\n\n\nknitr::kable(head(uebersax_fulldata))\n\n\n\nA\nB\nC\nD\n\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n\n\n\nFit the model using poLCA.\n\n\n\n\n\nflowchart TD\n  X((Disease)) --&gt; A\n  X --&gt; B\n  X --&gt; C\n  X --&gt; D\n\n\n\n\n\n\n\nf_ueber &lt;- cbind(A, B, C, D) ~ 1\nfit_ueber_polca &lt;- poLCA(f_ueber, data = uebersax_fulldata)\n\n\n ALERT: some manifest variables contain values that are not\n    positive integers. For poLCA to run, please recode categorical\n    outcome variables to increment from 1 to the maximum number of\n    outcome categories for each variable."
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_dependency.html#explanation-of-local-dependence",
    "href": "Labs/Day_3/Lab2/4_Lab_dependency.html#explanation-of-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "",
    "text": "The standard latent class “cluster” model specifies that the indicators \\(Y_1, Y_2, \\ldots, Y_p\\) should be conditionally independent, given the latent variable \\(X\\), say, \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = \\prod_{j = 1}^p P(Y_j | X).\n\\] The product on the right-hand side indicates this conditional independence.\nFor example, suppose four diagnostic tests \\(Y_j\\), for \\(j = 1, \\ldots, p = 4\\), have been used to test for a disease \\(X \\in \\{0, 1\\}\\). Then for all people within the “healthy” class (\\(X=0\\), say), the four diagnostic tests should be like four independent biased coin flips, and the same should apply in the “diseased” class. This would be violated, for instance, when on diagnostic test depends on the results of another (e.g. the results of one are used to determine another), or when two tests use the same biological technique, thus giving similar errors. The same concern can be found in the SEM literature under the term “error correlation”.\nLocal dependence is a violation of the assumptions. Instead of the model given above, if, say, indicators \\(Y_1\\) and \\(Y_2\\) are locally dependent, we cannot use the simple form given on the right-hand side in that equation, and we are forced to write \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = P(Y_1, Y_2 | X) \\prod_{j = 3}^p P(Y_j | X),\n\\] so we have to have a separate model for the conditional “cross-table” \\(P(Y_1, Y_2 | X)\\). Ignoring this can have consequences for the solution and your subsequent conclusions. In the first, locally independent, equation above, the sensitivity (\\(P(Y_j = 1 | X = 1)\\)) and specificity (\\(P(Y_j = 0 | X = 0)\\)) of two indicators will look high to the model if the indicators are strongly dependent. But when this dependence was due to an error correlation, the sensitivity and specificity will be overestimated. In the extreme case, imagine including the same completely random coin flip under two different names, with two excellent indicators of the latent variable. The latent class model will then output the exact opposite of the truth: the coin flips will look reliable, while the excellent indicators will look worthless, as you can verify for yourself below.\n\nlibrary(poLCA)\nset.seed(202302)\n\n\nn &lt;- 2*50L # Ensure sample size is even\nsensitivity &lt;- 0.8\nspecificity &lt;- 0.9\n\ntrue_x &lt;- rep(1:2, each = n/2) # Create true classes\nprobs_indicators &lt;- c(1 - specificity, sensitivity)[true_x]\n\n# The following is a single completely useless noise variable\n# (adding 1 is necessary because poLCA expects Y ∈ {1,2})\ngarbage_coinflip &lt;- rbinom(n, 1, prob = 0.5) + 1\n\n# Here are two excellent indicators of true_x, both with Se=0.8, Sp=0.9\ngreat_indicator1 &lt;- rbinom(n, 1, prob = probs_indicators) + 1\ngreat_indicator2 &lt;- rbinom(n, 1, prob = probs_indicators) + 1\n\n# The data contain two completely worthless indicators, which \n#   are completely dependent (in fact they are identical)\n# and two excellent indicators, which do have some small amount of error\nmade_up_data &lt;- data.frame(noise1 = garbage_coinflip, \n                noise2 = garbage_coinflip, \n                good1 = great_indicator1, \n                good2 = great_indicator2)\n\n# Run the latent class model using poLCA\nfit_polca &lt;- poLCA(cbind(noise1, noise2, good1, good2) ~ 1, nclass = 2, data = made_up_data)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$noise1\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$noise2\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$good1\n           Pr(1)  Pr(2)\nclass 1:  0.5000 0.5000\nclass 2:  0.6042 0.3958\n\n$good2\n           Pr(1)  Pr(2)\nclass 1:  0.5192 0.4808\nclass 2:  0.5417 0.4583\n\nEstimated class population shares \n 0.52 0.48 \n \nPredicted class memberships (by modal posterior prob.) \n 0.52 0.48 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 100 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -206.6095 \n \nAIC(2): 431.2189\nBIC(2): 454.6655\nG^2(2): 44.2938 (Likelihood ratio/deviance statistic) \nX^2(2): 40.92018 (Chi-square goodness of fit) \n \n\n\n\nlibrary(flexmix)\nfit_fm_ld_direct &lt;- \n  flexmix(~1, data = made_up_data-1, \n          k = 2, \n          model = list(\n            FLXMCmvbinary(noise1 ~ 1),\n            FLXMRglmfix(formula = cbind(noise2, 1-noise2) ~ 1, \n                        nested = list(k = 2, formula = ~ noise1),\n                        family = \"binomial\"), \n            FLXMCmvbinary(good1 ~ 1),\n            FLXMCmvbinary(good2 ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\nCall:\nflexmix(formula = ~1, data = made_up_data - 1, k = 2, model = list(FLXMCmvbinary(noise1 ~ \n    1), FLXMRglmfix(formula = cbind(noise2, 1 - noise2) ~ 1, \n    nested = list(k = 2, formula = ~noise1), family = \"binomial\"), \n    FLXMCmvbinary(good1 ~ 1), FLXMCmvbinary(good2 ~ 1)))\n\n       prior size post&gt;0 ratio\nComp.1  0.55   55    100  0.55\nComp.2  0.45   45    100  0.45\n\n'log Lik.' -184.6463 (df=10)\nAIC: 389.2926   BIC: 415.3443 \n\nparameters(fit_fm_ld_direct)\n\n[[1]]\nComp.1.center Comp.2.center \n    0.5273048     0.4222115 \n\n[[2]]\n                    Comp.1    Comp.2\ncoef.noise1       53.13213  53.13213\ncoef.(Intercept) -26.56607 -26.56607\n\n[[3]]\nComp.1.center Comp.2.center \n  0.003545498   0.995397964 \n\n[[4]]\nComp.1.center Comp.2.center \n    0.1794210     0.8249772 \n\n\nAs you can see, according to LCA, the locally dependent random noise items are perfect, while the very good indicators are almost worthless – exactly opposite to the truth. If you were so inclined, you could play around with the following elements to see how results might change:\n\nsensitivity and specificity values (currently \\(\\text{Se}=0.8\\), \\(\\text{Sp}=0.9\\));\nnumber of “good” indicators (currently two);\nnumber of dependent noise items (currently two);\nthe amount of local dependence (currently perfect dependence).\n\nIncluding an additional class can model this dependence. You can verify this by changing nclass = 2 to nclass = 3 above to see how results change. This may be a satisfactory solution there is no strong substantive reason to prefer a specific number of classes. For example, when mixture modeling is used as a density estimation technique, or when the analysis is exploratory. But you may not want to increase the number of classes when the latent classes are intended to have some predefined meaning, as is the case for our diagnostic testing example. In that case, we would like the two classes to signify “no disease” and “disease”, while possibly accounting for any local dependence.\n\nData from Uebersax (2009), https://www.john-uebersax.com/stat/condep.htm. These are data on four diagnostic tests for human HIV virus (Table 1) reported by Alvord et al. (1988).\n\nlibrary(tidyverse)\n\n# https://www.john-uebersax.com/stat/condep.htm\n\nlibrary(readr)\n\n# Load the dataset\nuebersax &lt;- read_table(\"https://raw.githubusercontent.com/lauraboeschoten/LCA_GESIS/main/Extra/Day_3/uebersax.tab\")\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  A = col_double(),\n  B = col_double(),\n  C = col_double(),\n  D = col_double(),\n  Freq = col_double()\n)\n\nuebersax01 &lt;- uebersax %&gt;% \n  mutate(across(A:D, ~ ifelse(.x == 1, 0, 1)),  # Convert 1 → 0 and 2 → 1\n         Freq = as.integer(Freq))  # Ensure Freq is an integer\n\nfrequencies_to_fulldata &lt;- function(df_freq) {\n  df_freq %&gt;%\n    uncount(Freq)\n}\n  \nuebersax_fulldata &lt;- frequencies_to_fulldata(uebersax)\n\nas.data.frame(table(uebersax_fulldata))\n\n   A B C D Freq\n1  1 1 1 1  170\n2  2 1 1 1    4\n3  1 2 1 1    6\n4  2 2 1 1    1\n5  1 1 2 1    0\n6  2 1 2 1    0\n7  1 2 2 1    0\n8  2 2 2 1    0\n9  1 1 1 2   15\n10 2 1 1 2   17\n11 1 2 1 2    0\n12 2 2 1 2    4\n13 1 1 2 2    0\n14 2 1 2 2   83\n15 1 2 2 2    0\n16 2 2 2 2  128\n\n\n\n\nTest\nDescription\n\n\n\nA\nRadioimmunoassay of antigen ag121\n\n\nB\nRadioimmunoassay of HIV p24\n\n\nC\nRadioimmunoassay of HIV gp120\n\n\nD\nEnzyme-linked immunosorbent assay\n\n\n\n\nknitr::kable(head(uebersax_fulldata))\n\n\n\nA\nB\nC\nD\n\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n\n\n\nFit the model using poLCA.\n\n\n\n\n\nflowchart TD\n  X((Disease)) --&gt; A\n  X --&gt; B\n  X --&gt; C\n  X --&gt; D\n\n\n\n\n\n\n\nf_ueber &lt;- cbind(A, B, C, D) ~ 1\nfit_ueber_polca &lt;- poLCA(f_ueber, data = uebersax_fulldata)\n\n\n ALERT: some manifest variables contain values that are not\n    positive integers. For poLCA to run, please recode categorical\n    outcome variables to increment from 1 to the maximum number of\n    outcome categories for each variable."
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_dependency.html#detecting-local-dependence",
    "href": "Labs/Day_3/Lab2/4_Lab_dependency.html#detecting-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Detecting local dependence",
    "text": "Detecting local dependence\nBivariate residuals\nWe first load a few convenience functions that work with poLCA objects from the poLCA.extras package. You may need to install this using remotes::install_github(\"daob/poLCA.extras\"). For this, you might need to install the remotes package first.\n\n#library(remotes)\n#remotes::install_github(\"daob/poLCA.extras\")\nlibrary(poLCA.extras)\n\n#bvr_ueber &lt;- bvr(fit_ueber_polca) \n#bvr_ueber |&gt; round(4) \n\nIndicators B and C appear to exhibit local dependence. That is the same conclusion reached by Uebersax. However, the BVRs are only approximately chi-square distributed, so they cannot be directly referred to a chi-square distribution. Instead we use a parametric bootstrap. The resulting bootstrapped \\(p\\)-values are:\n\n#pvals_boot &lt;- bootstrap_bvr_pvals(f_ueber, \n#                                  data = uebersax_fulldata,\n#                                  fit_polca = fit_ueber_polca,\n#                                  nclass = 2, nrep = 3)\n\n#pvals_boot\n\nSo, the parametric bootstrap of our BVR values confirms there appears to be a local dependence between indicators B and C.\nNow let’s look at the bivariate residuals for our extreme earlier example, with perfect error dependence of two noise variables.\n\n#bvr(fit_polca)\n\n# The bootstrap is not really necessary, and gives the \n#   expected result. If you wished to confirm this, you could \n#   uncomment the code below:\n#bootstrap_bvr_pvals(cbind(noise1, noise2, good1, good2) ~ 1, \n#                                  data = made_up_data,\n#                                  fit_polca = fit_polca,\n#                                  nclass = 2, nrep = 5)\n\nNote that the BVR detects local dependence, but the wrong pair of variables is singled out! This is because the latent class variable in the above, extreme, solution has taken over the role of the error dependence, while the “error dependence” is actually the substantively interesting disease status. While this is probably an extreme situation that is not particularly plausible in many applications. Still, it serves as an important warning that error dependencies found might not correspond to the “true” dependencies."
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_dependency.html#modeling-local-dependence",
    "href": "Labs/Day_3/Lab2/4_Lab_dependency.html#modeling-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Modeling local dependence",
    "text": "Modeling local dependence\nNow that we know:\n\nThere is strong local dependence, and\nThe local dependence can make a large difference to the results;\n\nwhat can we do about it? As mentioned above, the simplest solution is always to increase the number of classes. But when this is not desired there are some ways of keeping the number of classes the same, but allowing for dependence within those classes.\nJoint item method\n\n\n\n\n\nflowchart TD\n  X((Disease)) --&gt; A\n  X --&gt; BC\n  X --&gt; D\n\n\n\n\n\n\nFirst we reproduce the independence model, this time using flexmix.\n\nfit_fm &lt;- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax01, \n                  model = FLXMCmvbinary())\n\nround(parameters(fit_fm), 4)\n\n         Comp.1 Comp.2\ncenter.A 1.0000 0.0298\ncenter.B 0.5711 0.0356\ncenter.C 0.9129 0.0000\ncenter.D 1.0000 0.0806\n\nBIC(fit_fm)\n\n[1] 1314.297\n\n\nNext, we model the indicators B and C jointly, using a multinomial model. The same could be achieved by combining the two items into a single indicator, but here we have done that using the interaction() function within the model formula.\n\nfit_fm_ld &lt;- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax01, \n                  model = list(\n                    FLXMCmvbinary(A ~ 1),\n                    FLXMRmultinom(I(interaction(B, C)) ~ .),\n                    FLXMCmvbinary(D ~ 1))\n)\n\nparameters(fit_fm_ld)\n\n[[1]]\nComp.1.center Comp.2.center \n   0.99999999    0.02762255 \n\n[[2]]\n         Comp.1     Comp.2\ncoef1 -1.426238  -3.295796\ncoef2  1.610074 -13.355052\ncoef3  2.043265 -13.355052\n\n[[3]]\nComp.1.center Comp.2.center \n   0.99999948    0.07853297 \n\nBIC(fit_fm_ld)\n\n[1] 1313.246\n\n\nItem conditional probabilities can still be calculated by summing over the joint crosstable.\n\nest &lt;- fitted(fit_fm_ld)\n\nindices &lt;- with(uebersax01, \n     str_split(levels(interaction(B, C)), \"\\\\.\", \n               simplify = TRUE) |&gt;\n       apply(2, as.numeric))\n\ncbind(\n  B1 = tapply(est$Comp.1[1, 2:5], indices[, 1], sum),\n  B2 = tapply(est$Comp.2[1, 2:5], indices[, 1], sum),\n  C1 = tapply(est$Comp.1[1, 2:5], indices[, 2], sum),\n  C2 = tapply(est$Comp.2[1, 2:5], indices[, 2], sum)\n) |&gt; round(4)\n\n      B1     B2     C1 C2\n0 0.4301 0.9643 0.0888  1\n1 0.5699 0.0357 0.9112  0\n\n\nDirect effect method\nWith local dependence as a direct effect (Hagenaars), equal across classes\n\n\n\n\n\nflowchart TD\n  X((Disease)) --&gt; A\n  X --&gt; B\n  X --&gt; C\n  X --&gt; D\n  C --&gt; B\n\n\n\n\n\n\n\nfit_fm_ld_direct &lt;- \n  flexmix(~1, data = uebersax01, k = 2, \n          weights = ~Freq,\n          model = list(\n            FLXMCmvbinary(A ~ 1),\n            FLXMRglmfix(formula = cbind(B, 1-B) ~ 1, \n                        nested = list(k = 2, formula = ~ C),\n                        family = \"binomial\"), \n            FLXMCmvbinary(C ~ 1),\n            FLXMCmvbinary(D ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\nCall:\nflexmix(formula = ~1, data = uebersax01, k = 2, model = list(FLXMCmvbinary(A ~ \n    1), FLXMRglmfix(formula = cbind(B, 1 - B) ~ 1, nested = list(k = 2, \n    formula = ~C), family = \"binomial\"), FLXMCmvbinary(C ~ 1), \n    FLXMCmvbinary(D ~ 1)), weights = ~Freq)\n\n       prior size post&gt;0 ratio\nComp.1 0.459  196    217 0.903\nComp.2 0.541  232    232 1.000\n\n'log Lik.' -623.2971 (df=10)\nAIC: 1266.594   BIC: 1307.185 \n\nparameters(fit_fm_ld_direct) |&gt; lapply(round, 4)\n\n[[1]]\nComp.1.center Comp.2.center \n       0.0277        1.0000 \n\n[[2]]\n                  Comp.1  Comp.2\ncoef.C            1.8591  1.8591\ncoef.(Intercept) -3.2958 -1.4259\n\n[[3]]\nComp.1.center Comp.2.center \n       0.0000        0.9112 \n\n[[4]]\nComp.1.center Comp.2.center \n       0.0786        1.0000 \n\n\nWe can again calculate a conditional probability in each class for B, this time by summing over values of C. Because the model is conditional on C, this time we weight by the marginal of C, i.e. \\(P(B | X) = \\sum_C P(B | X, C) P(C)\\).\n\nP_B_given_XC &lt;- predict(fit_fm_ld_direct, \n                        newdata = data.frame(C=0:1))\n\nP_C &lt;- xtabs(Freq~C, data = uebersax01) |&gt; prop.table()\n\nc(Comp.1.avg=sum(P_B_given_XC[[1]][, 2] * P_C), \n  Comp.2.avg=sum(P_B_given_XC[[2]][, 2] * P_C))\n\nComp.1.avg Comp.2.avg \n 0.1127883  0.3972898 \n\n\nAdding local independence parameters\nWith Latent GOLD, we can make use of a loglinear latent class model formulation. This allows for full flexibility, including the addition of local dependence parameters that do not require an arbitrary choice of “dependent” observed variable.\n\n\n\n\n\nflowchart TD\n  X((Disease)) --&gt; A\n  X --&gt; B\n  X --&gt; C\n  X --&gt; D\n  C &lt;--&gt; B\n\n\n\n\n\n\n\nOpen the Uebersax data with Latent GOLD.\nFit a simple two-class latent class model with A, B, C, and D as the indicator variables. Do not forget to specify the Case Weight. You can do this either using the GUI or the syntax option.\nInspect the bivariate residuals. Confirm the local dependency between B and C.\nNow add the local dependence parameter to your model. You can gain do this using the GUI or syntax. In case you use the GUI, where did you find the option to include this parameter?\nCheck the bivariate residuals again. Have you solved the local dependency?\nCompare the fit of the independence model, and the local dependence model. What do you conclude here? Have the conditional response probabilities changes by including the local dependence parameter?"
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_multiple.html",
    "href": "Labs/Day_3/Lab2/4_Lab_multiple.html",
    "title": "Multiple latent variables LCA",
    "section": "",
    "text": "For this lab we will make use of the vote data from the LISS panel (as used in this paper https://doi.org/10.1007/s11634-015-0211-0). We will use these variables:\n\nA: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2008)\nB: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2009)\nC: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2010)\nD: Did you vote in the most recent parliamentary elections, held in 2010? (asked in 2011)\nE: Did you vote in the most recent parliamentary elections, held in 2010? (asked in 2012)\n\nQuestion 1\nOpen this dataset with Latent GOLD. Specify a model with indicator variables A, B, C, D and E loading onto one latent variable with two classes.\nQuestion 2\nSpecify a model with the following characteristics:\n\nIndicator variables A, B, C loading onto latent variable 1, which has two classes;\nIndicator variables D and E loading onto latent variable 2, which has two classes;\nAllow for a covariance between latent variable 1 and 2.\n\nQuestion 3\nCompare the fit of the model you fitted under Question 1 and under Question 2. Which model fits best?\nQuestion 4\nWhere in the profile do you find differences between the two models?"
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_multiple.html#multiple-latent-variables",
    "href": "Labs/Day_3/Lab2/4_Lab_multiple.html#multiple-latent-variables",
    "title": "Multiple latent variables LCA",
    "section": "",
    "text": "For this lab we will make use of the vote data from the LISS panel (as used in this paper https://doi.org/10.1007/s11634-015-0211-0). We will use these variables:\n\nA: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2008)\nB: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2009)\nC: Did you vote in the most recent parliamentary elections, held in 2006? (asked in 2010)\nD: Did you vote in the most recent parliamentary elections, held in 2010? (asked in 2011)\nE: Did you vote in the most recent parliamentary elections, held in 2010? (asked in 2012)\n\nQuestion 1\nOpen this dataset with Latent GOLD. Specify a model with indicator variables A, B, C, D and E loading onto one latent variable with two classes.\nQuestion 2\nSpecify a model with the following characteristics:\n\nIndicator variables A, B, C loading onto latent variable 1, which has two classes;\nIndicator variables D and E loading onto latent variable 2, which has two classes;\nAllow for a covariance between latent variable 1 and 2.\n\nQuestion 3\nCompare the fit of the model you fitted under Question 1 and under Question 2. Which model fits best?\nQuestion 4\nWhere in the profile do you find differences between the two models?"
  },
  {
    "objectID": "Labs/Day_3/Lab2/4_Lab_multiple.html#exploratory-versus-confirmatory",
    "href": "Labs/Day_3/Lab2/4_Lab_multiple.html#exploratory-versus-confirmatory",
    "title": "Multiple latent variables LCA",
    "section": "Exploratory versus confirmatory",
    "text": "Exploratory versus confirmatory\nFor this part of the lab, we work with the dataset political.sav. The dataset contains the following variables:\n\nSYS_RESP: System Responsiveness\nIDEO_LEV: Ideological Level\nREP_POT: Repression Potential\nPROT_APP: Protest Approval\nCONV_PAR: Convential Participation\nSEX: Sex\nEDUC: Education (training)\nAGE: Age (generation)\nFREQ: cell count\n\nOpen this dataset in Latent GOLD.\nQuestion 5\nRun a latent class model with one latent variable of two classes, and the variables SYS_REP, IDEO_LEV, REP_POT, PROT_APP and CONV_PAR as indicators.\nQuestion 6\nAn an exploratory latent class model where you model two latent variables, each with two latent classes, and each indicator loads on each latent variable.\nQuestion 7\nInspect the bivariate residuals of your model. Which variables load best onto which latent variable?\nQuestion 8\nRun a latent class model based on your conclusions of question 7."
  },
  {
    "objectID": "Labs/Day_3/Lab3/6_Lab_3step.html",
    "href": "Labs/Day_3/Lab3/6_Lab_3step.html",
    "title": "Ordinal indicators and 3-step modelling",
    "section": "",
    "text": "For this part of the lab, we will use the file GSS_82.sav. This dataset contains the following variables:\n\nID: Respondent id number\nACCURACY: Accuracy of surveys (mostly true / not true)\nCOOPERAT: Cooperation with the interviewer (interested / cooperative / impatient or hostile)\nUNDERSTA: Understanding of the survey questions (good / fair or poor)\nPURPOSE: Opinion on the purpose of surveys (good / depends / waste of time and money)\nRACE: Race of respondent\nSEX: Respondents sex\nEDUCR: Education level of respondent\nMARITAL: Marital status\nAGE: Age of respondent\n\nQuestion 1\nOpen this file with Latent GOLD and run a latent class model with a variable with 3 classes. Inspect the model fit.\nQuestion 2\nFor the variables with 3 categories, adjust the settings from nominal to ordinal. Inspect the model fit.\nQuestion 3\nCompare the number of degrees of freedom of both models. Can you explain the difference?\nQuestion 3\nCompare the difference between the profiles of the two models. What differenes do you see?\nQuestion 4\nCompare the model fit statistics of the two models. How are they different?"
  },
  {
    "objectID": "Labs/Day_3/Lab3/6_Lab_3step.html#ordinal-indicators",
    "href": "Labs/Day_3/Lab3/6_Lab_3step.html#ordinal-indicators",
    "title": "Ordinal indicators and 3-step modelling",
    "section": "",
    "text": "For this part of the lab, we will use the file GSS_82.sav. This dataset contains the following variables:\n\nID: Respondent id number\nACCURACY: Accuracy of surveys (mostly true / not true)\nCOOPERAT: Cooperation with the interviewer (interested / cooperative / impatient or hostile)\nUNDERSTA: Understanding of the survey questions (good / fair or poor)\nPURPOSE: Opinion on the purpose of surveys (good / depends / waste of time and money)\nRACE: Race of respondent\nSEX: Respondents sex\nEDUCR: Education level of respondent\nMARITAL: Marital status\nAGE: Age of respondent\n\nQuestion 1\nOpen this file with Latent GOLD and run a latent class model with a variable with 3 classes. Inspect the model fit.\nQuestion 2\nFor the variables with 3 categories, adjust the settings from nominal to ordinal. Inspect the model fit.\nQuestion 3\nCompare the number of degrees of freedom of both models. Can you explain the difference?\nQuestion 3\nCompare the difference between the profiles of the two models. What differenes do you see?\nQuestion 4\nCompare the model fit statistics of the two models. How are they different?"
  },
  {
    "objectID": "Labs/Day_3/Lab3/6_Lab_3step.html#three-step-modelling",
    "href": "Labs/Day_3/Lab3/6_Lab_3step.html#three-step-modelling",
    "title": "Ordinal indicators and 3-step modelling",
    "section": "Three-step modelling",
    "text": "Three-step modelling\nWe will first apply the ML approach to three-step modelling. We use the political.sav dataset that we used earlier today. It contains the following variables:\n\nSYS_RESP: System Responsiveness\nIDEO_LEV: Ideological Level\nREP_POT: Repression Potential\nPROT_APP: Protest Approval\nCONV_PAR: Convential Participation\nSEX: Sex\nEDUC: Education (training)\nAGE: Age (generation)\nFREQ: cell count\n\nQuestion 1\nOpen the political.sav dataset in Latent GOLD. Estimate a latent class model that has one latent variable consisting of 3 classes. The indicator variables loading on this LV are SYS_REP, IDEO_LEV, REP_POT, PROT_APP and CONV_PAR.\nMake sure that you store the posterior probabilities and the classification variable in a new dataset. See the lecture slides for an example syntax, or look into the Latent GOLD documentation.\nQuestion 2\nExplain how step 1 and step 2 of 3-step modelling now have been accounted for?\nQuestion 3\nOpen the dataset that you exported under question 1 and estimate the relationship between your LV and Sex. Do not apply the ML approach yet.\nQuestion 4 Now define the same model as under Question 3, but now using the ML approach (step 3). Look into the lecture slides or Latent GOLD documentation how to specify this.\nQuestion 5 Compare the parameter estimates between the two models. What differences do you see?\nQuestion 6 Explain in your own words how the ML approach accounts for the misclassification?"
  }
]