---
title: "Local dependence LCA in R"
author: "DL Oberski & L Boeschoten"
format:
  html:
    code-fold: false
    code-summary: "Show the code"
    code-tools: true
    code-link: true
    theme: forest
    toc: true
editor: visual
execute:
  cache: true
---

## Simulation example

The standard latent class "cluster" model specifies that the indicators $Y_1, Y_2, \ldots, Y_p$ should be *conditionally independent*, given the latent variable $X$, say, $$
P(Y_1, Y_2, \ldots, Y_p | X) = \prod_{j = 1}^p P(Y_j | X).
$$ The product on the right-hand side indicates this conditional independence.

For example, suppose four diagnostic tests $Y_j$, for $j = 1, \ldots, p = 4$, have been used to test for a disease $X \in \{0, 1\}$. Then for all people within the "healthy" class ($X=0$, say), the four diagnostic tests should be like four independent biased coin flips, and the same should apply in the "diseased" class. This would be violated, for instance, when on diagnostic test depends on the results of another (e.g. the results of one are used to determine another), or when two tests use the same biological technique, thus giving similar errors. The same concern can be found in the SEM literature under the term "error correlation".

Local dependence is a violation of the assumptions. Instead of the model given above, if, say, indicators $Y_1$ and $Y_2$ are locally dependent, we cannot use the simple form given on the right-hand side in that equation, and we are forced to write $$
P(Y_1, Y_2, \ldots, Y_p | X) = P(Y_1, Y_2 | X) \prod_{j = 3}^p P(Y_j | X),
$$ so we have to have a separate model for the conditional "cross-table" $P(Y_1, Y_2 | X)$. Ignoring this can have consequences for the solution and your subsequent conclusions. In the first, locally independent, equation above, the sensitivity ($P(Y_j = 1 | X = 1)$) and specificity ($P(Y_j = 0 | X = 0)$) of two indicators will look high to the model if the indicators are strongly dependent. But when this dependence was due to an error correlation, the sensitivity and specificity will be overestimated. In the extreme case, imagine including the same completely random coin flip under two different names, with two excellent indicators of the latent variable. The latent class model will then output the exact opposite of the truth: the coin flips will look reliable, while the excellent indicators will look worthless. We will verify this through the following questions. 

**Question 1**

Run the code below to simulate the local dependent data and an LC model. 

```{r, message=FALSE, warning=FALSE}
library(poLCA)
set.seed(202302)
```

```{r}
n <- 2*50L # Ensure sample size is even
sensitivity <- 0.8
specificity <- 0.9

true_x <- rep(1:2, each = n/2) # Create true classes
probs_indicators <- c(1 - specificity, sensitivity)[true_x]

# The following is a single completely useless noise variable
# (adding 1 is necessary because poLCA expects Y ∈ {1,2})
garbage_coinflip <- rbinom(n, 1, prob = 0.5) + 1

# Here are two excellent indicators of true_x, both with Se=0.8, Sp=0.9
great_indicator1 <- rbinom(n, 1, prob = probs_indicators) + 1
great_indicator2 <- rbinom(n, 1, prob = probs_indicators) + 1

# The data contain two completely worthless indicators, which 
#   are completely dependent (in fact they are identical)
# and two excellent indicators, which do have some small amount of error
made_up_data <- data.frame(noise1 = garbage_coinflip, 
                noise2 = garbage_coinflip, 
                good1 = great_indicator1, 
                good2 = great_indicator2)

# Run the latent class model using poLCA
fit_polca <- poLCA(cbind(noise1, noise2, good1, good2) ~ 1, nclass = 2, data = made_up_data)
```

```{r, warning=FALSE, message=FALSE}
library(flexmix)
fit_fm_ld_direct <- 
  flexmix(~1, data = made_up_data-1, 
          k = 2, 
          model = list(
            FLXMCmvbinary(noise1 ~ 1),
            FLXMRglmfix(formula = cbind(noise2, 1-noise2) ~ 1, 
                        nested = list(k = 2, formula = ~ noise1),
                        family = "binomial"), 
            FLXMCmvbinary(good1 ~ 1),
            FLXMCmvbinary(good2 ~ 1)))

summary(fit_fm_ld_direct)
parameters(fit_fm_ld_direct)
```

**Question 2**

Confirm that, according to the LCA, the locally dependent random noise items are perfect, while the very good indicators are almost worthless -- exactly opposite to the truth. If you were so inclined, you could play around with the following elements to see how results might change:

-   sensitivity and specificity values (currently $\text{Se}=`r sensitivity`$, $\text{Sp}=`r specificity`$);
-   number of "good" indicators (currently two);
-   number of dependent noise items (currently two);
-   the amount of local dependence (currently perfect dependence).

**Question 3**

Including an additional class can model this dependence. You can verify this by changing `nclass = 2` to `nclass = 3` above to see how results change. This may be a satisfactory solution there is no strong substantive reason to prefer a specific number of classes. For example, when mixture modeling is used as a density estimation technique, or when the analysis is exploratory. But you may not want to increase the number of classes when the latent classes are intended to have some predefined meaning, as is the case for our diagnostic testing example. In that case, we would like the two classes to signify "no disease" and "disease", while possibly accounting for any local dependence.

### Example with data

Data from Uebersax (2009), <https://www.john-uebersax.com/stat/condep.htm>. These are data on four diagnostic tests for human HIV virus (Table 1) reported by Alvord et al. (1988).

**Question 4**

Load the data 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)

# https://www.john-uebersax.com/stat/condep.htm

library(readr)

# Load the dataset
uebersax <- read_table("https://raw.githubusercontent.com/lauraboeschoten/LCA_GESIS/main/Extra/Day_3/uebersax.tab")

uebersax01 <- uebersax %>% 
  mutate(across(A:D, ~ ifelse(.x == 1, 0, 1)),  # Convert 1 → 0 and 2 → 1
         Freq = as.integer(Freq))  # Ensure Freq is an integer

frequencies_to_fulldata <- function(df_freq) {
  df_freq %>%
    uncount(Freq)
}
  
uebersax_fulldata <- frequencies_to_fulldata(uebersax)

as.data.frame(table(uebersax_fulldata))

```

| Test | Description                       |
|------|-----------------------------------|
| A    | Radioimmunoassay of antigen ag121 |
| B    | Radioimmunoassay of HIV p24       |
| C    | Radioimmunoassay of HIV gp120     |
| D    | Enzyme-linked immunosorbent assay |

```{r}
knitr::kable(head(uebersax_fulldata))
```

**Question 5**

Fit the 2 class model using `poLCA`.

```{mermaid}
flowchart TD
  X((Disease)) --> A
  X --> B
  X --> C
  X --> D
```

```{r, warning=FALSE, message=FALSE}
library(poLCA)

f_ueber <- cbind(A, B, C, D) ~ 1
fit_ueber_polca <- poLCA(f_ueber, 
                         data = uebersax_fulldata,
                         nclass = 2)
```

## Detecting local dependence

### Bivariate residuals

We first load a few convenience functions that work with `poLCA` objects from the `poLCA.extras` package. You may need to install this using `remotes::install_github("daob/poLCA.extras")`. For this, you might need to install the `remotes` package first.

```{r}
#library(remotes)
#remotes::install_github("daob/poLCA.extras")
library(poLCA.extras)
```

**Question 6**

Calculate the bivariate residuals and interpret them. Do you spot a local dependency?

```{r}
bvr_ueber <- bvr(fit_ueber_polca) 
bvr_ueber |> round(4) 
```

**Question 7**

The BVRs are only approximately chi-square distributed, so they cannot be directly referred to a chi-square distribution. Calculate p-values using a parametric bootstrap.

```{r}
pvals_boot <- bootstrap_bvr_pvals(f_ueber, 
                                  data = uebersax_fulldata,
                                  fit_polca = fit_ueber_polca,
                                  nclass = 2, nrep = 3)

pvals_boot
```

**Question 8**

Now let's look at the bivariate residuals for our extreme earlier example, with perfect error dependence of two noise variables.

```{r}
bvr(fit_polca)

# The bootstrap is not really necessary, and gives the 
#   expected result. If you wished to confirm this, you could 
#   uncomment the code below:
#bootstrap_bvr_pvals(cbind(noise1, noise2, good1, good2) ~ 1, 
#                                  data = made_up_data,
#                                  fit_polca = fit_polca,
#                                  nclass = 2, nrep = 5)
```

Note that the BVR detects local dependence, but the wrong pair of variables is singled out! This is because the latent class variable in the above, extreme, solution has taken over the role of the error dependence, while the "error dependence" is actually the substantively interesting disease status. While this is probably an extreme situation that is not particularly plausible in many applications. Still, it serves as an important warning that error dependencies found might not correspond to the "true" dependencies.

## Modeling local dependence

Now that we know:

-   There is strong local dependence, and
-   The local dependence can make a large difference to the results;

what can we do about it? As mentioned above, the simplest solution is always to increase the number of classes. But when this is not desired there are some ways of keeping the number of classes the same, but allowing for dependence within those classes.

### Joint item method

```{mermaid}
flowchart TD
  X((Disease)) --> A
  X --> BC
  X --> D
```

**Question 9**

Reproduce the independence model first, this time using `flexmix`.

```{r}
fit_fm <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, 
                  weights = ~Freq,
                  data = uebersax01, 
                  model = FLXMCmvbinary())

round(parameters(fit_fm), 4)
BIC(fit_fm)
```

**Question 10**

Model the indicators B and C jointly, using a multinomial model. The same could be achieved by combining the two items into a single indicator, but here we have done that using the `interaction()` function within the model formula.

```{r}
fit_fm_ld <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, 
                  weights = ~Freq,
                  data = uebersax01, 
                  model = list(
                    FLXMCmvbinary(A ~ 1),
                    FLXMRmultinom(I(interaction(B, C)) ~ .),
                    FLXMCmvbinary(D ~ 1))
)
```

**Question 11**

Evaluate the parameters and the fit of the model. 

```{r}
parameters(fit_fm_ld)
BIC(fit_fm_ld)
```

**Question 12**

Calculate the item conditional response probabilities by summing over the joint crosstable.

```{r}
est <- fitted(fit_fm_ld)

indices <- with(uebersax01, 
     str_split(levels(interaction(B, C)), "\\.", 
               simplify = TRUE) |>
       apply(2, as.numeric))

cbind(
  B1 = tapply(est$Comp.1[1, 2:5], indices[, 1], sum),
  B2 = tapply(est$Comp.2[1, 2:5], indices[, 1], sum),
  C1 = tapply(est$Comp.1[1, 2:5], indices[, 2], sum),
  C2 = tapply(est$Comp.2[1, 2:5], indices[, 2], sum)
) |> round(4)
```


### Adding local independence parameters

With Latent GOLD, we can make use of a loglinear latent class model formulation. This allows for full flexibility, including the addition of local dependence parameters that do not require an arbitrary choice of "dependent" observed variable.

```{mermaid}
flowchart TD
  X((Disease)) --> A
  X --> B
  X --> C
  X --> D
  C <--> B
```

**Question 13**

Open the Uebersax data with Latent GOLD.

**Question 14**

Fit a simple two-class latent class model with A, B, C, and D as the indicator variables. Do not forget to specify the Case Weight. You can do this either using the GUI or the syntax option.

**Question 15**

Inspect the bivariate residuals. Confirm the local dependency between B and C.

**Question 16**

Now add the local dependence parameter to your model. You can gain do this using the GUI or syntax. In case you use the GUI, where did you find the option to include this parameter?

**Question 17**

Check the bivariate residuals again. Have you solved the local dependency?

**Question 18**

Compare the fit of the independence model, and the local dependence model. What do you conclude here? Have the conditional response probabilities changes by including the local dependence parameter?
